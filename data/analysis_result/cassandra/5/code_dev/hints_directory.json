{
    "performance_sensitive": "Yes",
    "config_name": "hints_directory",
    "messages": [
        {
            "sender": "System",
            "content": "Initialize the analysis for the target system and configuration."
        },
        {
            "sender": "Developer",
            "content": "@VisibleForTesting\n    HintsService(IFailureDetector failureDetector)\n    {\n        File hintsDirectory = DatabaseDescriptor.getHintsDirectory();\n        int maxDeliveryThreads = DatabaseDescriptor.getMaxHintsDeliveryThreads();\n\n        catalog = HintsCatalog.load(hintsDirectory, createDescriptorParams());\n        writeExecutor = new HintsWriteExecutor(catalog);\n\n        int bufferSize = Math.max(DatabaseDescriptor.getMaxMutationSize() * 2, MIN_BUFFER_SIZE);\n        bufferPool = new HintsBufferPool(bufferSize, writeExecutor::flushBuffer);\n\n        isDispatchPaused = new AtomicBoolean(true);\n        dispatchExecutor = new HintsDispatchExecutor(hintsDirectory, maxDeliveryThreads, isDispatchPaused, failureDetector::isAlive);\n\n        // periodically empty the current content of the buffers\n        int flushPeriod = DatabaseDescriptor.getHintsFlushPeriodInMS();\n        triggerFlushingFuture = ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(() -> writeExecutor.flushBufferPool(bufferPool),\n                                                                                        flushPeriod,\n                                                                                        flushPeriod,\n                                                                                        TimeUnit.MILLISECONDS);\n        metrics = new HintedHandoffMetrics();\n    }\n\n    \npublic void execute()\n        {\n            if (FBUtilities.isWindows)\n                return;\n            String jemalloc = System.getProperty(\"cassandra.libjemalloc\");\n            if (jemalloc == null)\n                logger.warn(\"jemalloc shared library could not be preloaded to speed up memory allocations\");\n            else if (\"-\".equals(jemalloc))\n                logger.info(\"jemalloc preload explicitly disabled\");\n            else\n                logger.info(\"jemalloc seems to be preloaded from {}\", jemalloc);\n        }\n    }\npublic void execute() throws StartupException\n        {\n            long now = System.currentTimeMillis();\n            if (now < EARLIEST_LAUNCH_DATE)\n                throw new StartupException(StartupException.ERR_WRONG_MACHINE_STATE,\n                                           String.format(\"current machine time is %s, but that is seemingly incorrect. exiting now.\",\n                                                         new Date(now).toString()));\n        }\n    }\npublic void execute()\n        {\n            String jmxPort = System.getProperty(\"cassandra.jmx.remote.port\");\n            if (jmxPort == null)\n            {\n                logger.warn(\"JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.\");\n                jmxPort = System.getProperty(\"cassandra.jmx.local.port\");\n                if (jmxPort == null)\n                    logger.error(\"cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.\");\n            }\n            else\n            {\n                logger.info(\"JMX is enabled to receive remote connections on port: {}\", jmxPort);\n            }\n        }\n    }\npublic void execute()\n        {\n            if (COM_SUN_MANAGEMENT_JMXREMOTE_PORT.isPresent())\n            {\n                logger.warn(\"Use of com.sun.management.jmxremote.port at startup is deprecated. \" +\n                            \"Please use cassandra.jmx.remote.port instead.\");\n            }\n        }\n    }\npublic void execute()\n        {\n            // log warnings for different kinds of sub-optimal JVMs.  tldr use 64-bit Oracle >= 1.6u32\n            if (!DatabaseDescriptor.hasLargeAddressSpace())\n                logger.warn(\"32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM for better performance.\");\n\n            String javaVmName = JAVA_VM_NAME.getString();\n            if (!(javaVmName.contains(\"HotSpot\") || javaVmName.contains(\"OpenJDK\")))\n            {\n                logger.warn(\"Non-Oracle JVM detected.  Some features, such as immediate unmap of compacted SSTables, may not work as intended\");\n            }\n            else\n            {\n                checkOutOfMemoryHandling();\n            }\n        }\n\n        \npublic void execute() throws StartupException\n        {\n            // Fail-fast if the native library could not be linked.\n            if (!NativeLibrary.isAvailable())\n                throw new StartupException(StartupException.ERR_WRONG_MACHINE_STATE, \"The native library could not be initialized properly. \");\n        }\n    }\npublic void execute()\n        {\n            SigarLibrary.instance.warnIfRunningInDegradedMode();\n        }\n    }\npublic void execute()\n        {\n            if (!FBUtilities.isLinux)\n                return;\n\n            if (DatabaseDescriptor.getDiskAccessMode() == Config.DiskAccessMode.standard &&\n                DatabaseDescriptor.getIndexAccessMode() == Config.DiskAccessMode.standard)\n                return; // no need to check if disk access mode is only standard and not mmap\n\n            long maxMapCount = getMaxMapCount();\n            if (maxMapCount < EXPECTED_MAX_MAP_COUNT)\n                logger.warn(\"Maximum number of memory map areas per process (vm.max_map_count) {} \" +\n                            \"is too low, recommended value: {}, you can change it with sysctl.\",\n                            maxMapCount, EXPECTED_MAX_MAP_COUNT);\n        }\n    }\npublic void execute() throws StartupException\n        {\n            final Set<String> invalid = new HashSet<>();\n            final Set<String> nonSSTablePaths = new HashSet<>();\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getCommitLogLocation()));\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getSavedCachesLocation()));\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getHintsDirectory()));\n\n            FileVisitor<Path> sstableVisitor = new SimpleFileVisitor<Path>()\n            {\n                public FileVisitResult visitFile(Path path, BasicFileAttributes attrs)\n                {\n                    File file = path.toFile();\n                    if (!Descriptor.isValidFile(file))\n                        return FileVisitResult.CONTINUE;\n\n                    try\n                    {\n                        if (!Descriptor.fromFilename(file).isCompatible())\n                            invalid.add(file.toString());\n                    }\n                    catch (Exception e)\n                    {\n                        invalid.add(file.toString());\n                    }\n                    return FileVisitResult.CONTINUE;\n                }\n\n                public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException\n                {\n                    String name = dir.getFileName().toString();\n                    return (name.equals(Directories.SNAPSHOT_SUBDIR)\n                            || name.equals(Directories.BACKUPS_SUBDIR)\n                            || nonSSTablePaths.contains(dir.toFile().getCanonicalPath()))\n                           ? FileVisitResult.SKIP_SUBTREE\n                           : FileVisitResult.CONTINUE;\n                }\n            };\n\n            for (String dataDir : DatabaseDescriptor.getAllDataFileLocations())\n            {\n                try\n                {\n                    Files.walkFileTree(Paths.get(dataDir), sstableVisitor);\n                }\n                catch (IOException e)\n                {\n                    throw new StartupException(3, \"Unable to verify sstable files on disk\", e);\n                }\n            }\n\n            if (!invalid.isEmpty())\n                throw new StartupException(StartupException.ERR_WRONG_DISK_STATE,\n                                           String.format(\"Detected unreadable sstables %s, please check \" +\n                                                         \"NEWS.txt and ensure that you have upgraded through \" +\n                                                         \"all required intermediate versions, running \" +\n                                                         \"upgradesstables\",\n                                                         Joiner.on(\",\").join(invalid)));\n\n        }\n    }\npublic void execute() throws StartupException\n        {\n            // check the system keyspace to keep user from shooting self in foot by changing partitioner, cluster name, etc.\n            // we do a one-off scrub of the system keyspace first; we can't load the list of the rest of the keyspaces,\n            // until system keyspace is opened.\n\n            for (TableMetadata cfm : Schema.instance.getTablesAndViews(SchemaConstants.SYSTEM_KEYSPACE_NAME))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n\n            try\n            {\n                SystemKeyspace.checkHealth();\n            }\n            catch (ConfigurationException e)\n            {\n                throw new StartupException(StartupException.ERR_WRONG_CONFIG, \"Fatal exception during initialization\", e);\n            }\n        }\n    }\npublic void execute() throws StartupException\n        {\n            if (!Boolean.getBoolean(\"cassandra.ignore_dc\"))\n            {\n                String storedDc = SystemKeyspace.getDatacenter();\n                if (storedDc != null)\n                {\n                    String currentDc = DatabaseDescriptor.getEndpointSnitch().getLocalDatacenter();\n                    if (!storedDc.equals(currentDc))\n                    {\n                        String formatMessage = \"Cannot start node if snitch's data center (%s) differs from previous data center (%s). \" +\n                                               \"Please fix the snitch configuration, decommission and rebootstrap this node or use the flag -Dcassandra.ignore_dc=true.\";\n\n                        throw new StartupException(StartupException.ERR_WRONG_CONFIG, String.format(formatMessage, currentDc, storedDc));\n                    }\n                }\n            }\n        }\n    }\npublic void execute() throws StartupException\n        {\n            if (!Boolean.getBoolean(\"cassandra.ignore_rack\"))\n            {\n                String storedRack = SystemKeyspace.getRack();\n                if (storedRack != null)\n                {\n                    String currentRack = DatabaseDescriptor.getEndpointSnitch().getLocalRack();\n                    if (!storedRack.equals(currentRack))\n                    {\n                        String formatMessage = \"Cannot start node if snitch's rack (%s) differs from previous rack (%s). \" +\n                                               \"Please fix the snitch configuration, decommission and rebootstrap this node or use the flag -Dcassandra.ignore_rack=true.\";\n\n                        throw new StartupException(StartupException.ERR_WRONG_CONFIG, String.format(formatMessage, currentRack, storedRack));\n                    }\n                }\n            }\n        }\n    }\n/**\n * Verifies that the system and environment is in a fit state to be started.\n * Used in CassandraDaemon#setup() to check various settings and invariants.\n *\n * Each individual test is modelled as an implementation of StartupCheck, these are run\n * at the start of CassandraDaemon#setup() before any local state is mutated. The default\n * checks are a mix of informational tests (inspectJvmOptions), initialization\n * (initSigarLibrary, checkCacheServiceInitialization) and invariant checking\n * (checkValidLaunchDate, checkSystemKeyspaceState, checkSSTablesFormat).\n *\n * In addition, if checkSystemKeyspaceState determines that the release version has\n * changed since last startup (i.e. the node has been upgraded) it snapshots the system\n * keyspace to make it easier to back out if necessary.\n *\n * If any check reports a failure, then the setup method exits with an error (after\n * logging any output from the tests). If all tests report success, setup can continue.\n * We should be careful in future to ensure anything which mutates local state (such as\n * writing new sstables etc) only happens after we've verified the initial setup.\n */\npublic class StartupChecks\n{\n    private static final Logger logger = LoggerFactory.getLogger(StartupChecks.class);\n    // List of checks to run before starting up. If any test reports failure, startup will be halted.\n    private final List<StartupCheck> preFlightChecks = new ArrayList<>();\n\n    // The default set of pre-flight checks to run. Order is somewhat significant in that we probably\n    // always want the system keyspace check run last, as this actually loads the schema for that\n    // keyspace. All other checks should not require any schema initialization.\n    private final List<StartupCheck> DEFAULT_TESTS = ImmutableList.of(checkJemalloc,\n                                                                      checkLz4Native,\n                                                                      checkValidLaunchDate,\n                                                                      checkJMXPorts,\n                                                                      checkJMXProperties,\n                                                                      inspectJvmOptions,\n                                                                      checkNativeLibraryInitialization,\n                                                                      initSigarLibrary,\n                                                                      checkMaxMapCount,\n                                                                      checkDataDirs,\n                                                                      checkSSTablesFormat,\n                                                                      checkSystemKeyspaceState,\n                                                                      checkDatacenter,\n                                                                      checkRack,\n                                                                      checkLegacyAuthTables);\n\n    public StartupChecks withDefaultTests()\n    {\n        preFlightChecks.addAll(DEFAULT_TESTS);\n        return this;\n    }\n\n    /**\n     * Add system test to be run before schema is loaded during startup\n     * @param test the system test to include\n     */\n    public StartupChecks withTest(StartupCheck test)\n    {\n        preFlightChecks.add(test);\n        return this;\n    }\n\n    /**\n     * Run the configured tests and return a report detailing the results.\n     * @throws org.apache.cassandra.exceptions.StartupException if any test determines that the\n     * system is not in an valid state to startup\n     */\n    public void verify() throws StartupException\n    {\n        for (StartupCheck test : preFlightChecks)\n            test.execute();\n    }\n\n    public static final StartupCheck checkJemalloc = new StartupCheck()\n    {\n        public void execute()\n        {\n            if (FBUtilities.isWindows)\n                return;\n            String jemalloc = System.getProperty(\"cassandra.libjemalloc\");\n            if (jemalloc == null)\n                logger.warn(\"jemalloc shared library could not be preloaded to speed up memory allocations\");\n            else if (\"-\".equals(jemalloc))\n                logger.info(\"jemalloc preload explicitly disabled\");\n            else\n                logger.info(\"jemalloc seems to be preloaded from {}\", jemalloc);\n        }\n    };\n\n    public static final StartupCheck checkLz4Native = () -> {\n        try\n        {\n            LZ4Factory.nativeInstance(); // make sure native loads\n        }\n        catch (AssertionError | LinkageError e)\n        {\n            logger.warn(\"lz4-java was unable to load native libraries; this will lower the performance of lz4 (network/sstables/etc.): {}\", Throwables.getRootCause(e).getMessage());\n        }\n    };\n\n    public static final StartupCheck checkValidLaunchDate = new StartupCheck()\n    {\n        /**\n         * The earliest legit timestamp a casandra instance could have ever launched.\n         * Date roughly taken from http://perspectives.mvdirona.com/2008/07/12/FacebookReleasesCassandraAsOpenSource.aspx\n         * We use this to ensure the system clock is at least somewhat correct at startup.\n         */\n        private static final long EARLIEST_LAUNCH_DATE = 1215820800000L;\n        public void execute() throws StartupException\n        {\n            long now = System.currentTimeMillis();\n            if (now < EARLIEST_LAUNCH_DATE)\n                throw new StartupException(StartupException.ERR_WRONG_MACHINE_STATE,\n                                           String.format(\"current machine time is %s, but that is seemingly incorrect. exiting now.\",\n                                                         new Date(now).toString()));\n        }\n    };\n\n    public static final StartupCheck checkJMXPorts = new StartupCheck()\n    {\n        public void execute()\n        {\n            String jmxPort = System.getProperty(\"cassandra.jmx.remote.port\");\n            if (jmxPort == null)\n            {\n                logger.warn(\"JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.\");\n                jmxPort = System.getProperty(\"cassandra.jmx.local.port\");\n                if (jmxPort == null)\n                    logger.error(\"cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.\");\n            }\n            else\n            {\n                logger.info(\"JMX is enabled to receive remote connections on port: {}\", jmxPort);\n            }\n        }\n    };\n\n    public static final StartupCheck checkJMXProperties = new StartupCheck()\n    {\n        public void execute()\n        {\n            if (COM_SUN_MANAGEMENT_JMXREMOTE_PORT.isPresent())\n            {\n                logger.warn(\"Use of com.sun.management.jmxremote.port at startup is deprecated. \" +\n                            \"Please use cassandra.jmx.remote.port instead.\");\n            }\n        }\n    };\n\n    public static final StartupCheck inspectJvmOptions = new StartupCheck()\n    {\n        public void execute()\n        {\n            // log warnings for different kinds of sub-optimal JVMs.  tldr use 64-bit Oracle >= 1.6u32\n            if (!DatabaseDescriptor.hasLargeAddressSpace())\n                logger.warn(\"32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM for better performance.\");\n\n            String javaVmName = JAVA_VM_NAME.getString();\n            if (!(javaVmName.contains(\"HotSpot\") || javaVmName.contains(\"OpenJDK\")))\n            {\n                logger.warn(\"Non-Oracle JVM detected.  Some features, such as immediate unmap of compacted SSTables, may not work as intended\");\n            }\n            else\n            {\n                checkOutOfMemoryHandling();\n            }\n        }\n\n        /**\n         * Checks that the JVM is configured to handle OutOfMemoryError\n         */\n        private void checkOutOfMemoryHandling()\n        {\n            if (JavaUtils.supportExitOnOutOfMemory(JAVA_VERSION.getString()))\n            {\n                if (!jvmOptionsContainsOneOf(\"-XX:OnOutOfMemoryError=\", \"-XX:+ExitOnOutOfMemoryError\", \"-XX:+CrashOnOutOfMemoryError\"))\n                    logger.warn(\"The JVM is not configured to stop on OutOfMemoryError which can cause data corruption.\"\n                                + \" Use one of the following JVM options to configure the behavior on OutOfMemoryError: \"\n                                + \" -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError=\\\"<cmd args>;<cmd args>\\\"\");\n            }\n            else\n            {\n                if (!jvmOptionsContainsOneOf(\"-XX:OnOutOfMemoryError=\"))\n                    logger.warn(\"The JVM is not configured to stop on OutOfMemoryError which can cause data corruption.\"\n                            + \" Either upgrade your JRE to a version greater or equal to 8u92 and use -XX:+ExitOnOutOfMemoryError/-XX:+CrashOnOutOfMemoryError\"\n                            + \" or use -XX:OnOutOfMemoryError=\\\"<cmd args>;<cmd args>\\\" on your current JRE.\");\n            }\n        }\n\n        /**\n         * Checks if one of the specified options is being used.\n         * @param optionNames The name of the options to check\n         * @return {@code true} if one of the specified options is being used, {@code false} otherwise.\n         */\n        private boolean jvmOptionsContainsOneOf(String... optionNames)\n        {\n            RuntimeMXBean runtimeMxBean = ManagementFactory.getRuntimeMXBean();\n            List<String> inputArguments = runtimeMxBean.getInputArguments();\n            for (String argument : inputArguments)\n            {\n                for (String optionName : optionNames)\n                    if (argument.startsWith(optionName))\n                        return true;\n            }\n            return false;\n        }\n    };\n\n    public static final StartupCheck checkNativeLibraryInitialization = new StartupCheck()\n    {\n        public void execute() throws StartupException\n        {\n            // Fail-fast if the native library could not be linked.\n            if (!NativeLibrary.isAvailable())\n                throw new StartupException(StartupException.ERR_WRONG_MACHINE_STATE, \"The native library could not be initialized properly. \");\n        }\n    };\n\n    public static final StartupCheck initSigarLibrary = new StartupCheck()\n    {\n        public void execute()\n        {\n            SigarLibrary.instance.warnIfRunningInDegradedMode();\n        }\n    };\n\n    public static final StartupCheck checkMaxMapCount = new StartupCheck()\n    {\n        private final long EXPECTED_MAX_MAP_COUNT = 1048575;\n        private final String MAX_MAP_COUNT_PATH = \"/proc/sys/vm/max_map_count\";\n\n        private long getMaxMapCount()\n        {\n            final Path path = Paths.get(MAX_MAP_COUNT_PATH);\n            try (final BufferedReader bufferedReader = Files.newBufferedReader(path))\n            {\n                final String data = bufferedReader.readLine();\n                if (data != null)\n                {\n                    try\n                    {\n                        return Long.parseLong(data);\n                    }\n                    catch (final NumberFormatException e)\n                    {\n                        logger.warn(\"Unable to parse {}.\", path, e);\n                    }\n                }\n            }\n            catch (final IOException e)\n            {\n                logger.warn(\"IO exception while reading file {}.\", path, e);\n            }\n            return -1;\n        }\n\n        public void execute()\n        {\n            if (!FBUtilities.isLinux)\n                return;\n\n            if (DatabaseDescriptor.getDiskAccessMode() == Config.DiskAccessMode.standard &&\n                DatabaseDescriptor.getIndexAccessMode() == Config.DiskAccessMode.standard)\n                return; // no need to check if disk access mode is only standard and not mmap\n\n            long maxMapCount = getMaxMapCount();\n            if (maxMapCount < EXPECTED_MAX_MAP_COUNT)\n                logger.warn(\"Maximum number of memory map areas per process (vm.max_map_count) {} \" +\n                            \"is too low, recommended value: {}, you can change it with sysctl.\",\n                            maxMapCount, EXPECTED_MAX_MAP_COUNT);\n        }\n    };\n\n    public static final StartupCheck checkDataDirs = () ->\n    {\n        // check all directories(data, commitlog, saved cache) for existence and permission\n        Iterable<String> dirs = Iterables.concat(Arrays.asList(DatabaseDescriptor.getAllDataFileLocations()),\n                                                 Arrays.asList(DatabaseDescriptor.getCommitLogLocation(),\n                                                               DatabaseDescriptor.getSavedCachesLocation(),\n                                                               DatabaseDescriptor.getHintsDirectory().getAbsolutePath()));\n\n        for (String dataDir : dirs)\n        {\n            logger.debug(\"Checking directory {}\", dataDir);\n            File dir = new File(dataDir);\n\n            // check that directories exist.\n            if (!dir.exists())\n            {\n                logger.warn(\"Directory {} doesn't exist\", dataDir);\n                // if they don't, failing their creation, stop cassandra.\n                if (!dir.mkdirs())\n                    throw new StartupException(StartupException.ERR_WRONG_DISK_STATE,\n                                               \"Has no permission to create directory \"+ dataDir);\n            }\n\n            // if directories exist verify their permissions\n            if (!Directories.verifyFullPermissions(dir, dataDir))\n                throw new StartupException(StartupException.ERR_WRONG_DISK_STATE,\n                                           \"Insufficient permissions on directory \" + dataDir);\n        }\n    };\n\n    public static final StartupCheck checkSSTablesFormat = new StartupCheck()\n    {\n        public void execute() throws StartupException\n        {\n            final Set<String> invalid = new HashSet<>();\n            final Set<String> nonSSTablePaths = new HashSet<>();\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getCommitLogLocation()));\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getSavedCachesLocation()));\n            nonSSTablePaths.add(FileUtils.getCanonicalPath(DatabaseDescriptor.getHintsDirectory()));\n\n            FileVisitor<Path> sstableVisitor = new SimpleFileVisitor<Path>()\n            {\n                public FileVisitResult visitFile(Path path, BasicFileAttributes attrs)\n                {\n                    File file = path.toFile();\n                    if (!Descriptor.isValidFile(file))\n                        return FileVisitResult.CONTINUE;\n\n                    try\n                    {\n                        if (!Descriptor.fromFilename(file).isCompatible())\n                            invalid.add(file.toString());\n                    }\n                    catch (Exception e)\n                    {\n                        invalid.add(file.toString());\n                    }\n                    return FileVisitResult.CONTINUE;\n                }\n\n                public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException\n                {\n                    String name = dir.getFileName().toString();\n                    return (name.equals(Directories.SNAPSHOT_SUBDIR)\n                            || name.equals(Directories.BACKUPS_SUBDIR)\n                            || nonSSTablePaths.contains(dir.toFile().getCanonicalPath()))\n                           ? FileVisitResult.SKIP_SUBTREE\n                           : FileVisitResult.CONTINUE;\n                }\n            };\n\n            for (String dataDir : DatabaseDescriptor.getAllDataFileLocations())\n            {\n                try\n                {\n                    Files.walkFileTree(Paths.get(dataDir), sstableVisitor);\n                }\n                catch (IOException e)\n                {\n                    throw new StartupException(3, \"Unable to verify sstable files on disk\", e);\n                }\n            }\n\n            if (!invalid.isEmpty())\n                throw new StartupException(StartupException.ERR_WRONG_DISK_STATE,\n                                           String.format(\"Detected unreadable sstables %s, please check \" +\n                                                         \"NEWS.txt and ensure that you have upgraded through \" +\n                                                         \"all required intermediate versions, running \" +\n                                                         \"upgradesstables\",\n                                                         Joiner.on(\",\").join(invalid)));\n\n        }\n    };\n\n    public static final StartupCheck checkSystemKeyspaceState = new StartupCheck()\n    {\n        public void execute() throws StartupException\n        {\n            // check the system keyspace to keep user from shooting self in foot by changing partitioner, cluster name, etc.\n            // we do a one-off scrub of the system keyspace first; we can't load the list of the rest of the keyspaces,\n            // until system keyspace is opened.\n\n            for (TableMetadata cfm : Schema.instance.getTablesAndViews(SchemaConstants.SYSTEM_KEYSPACE_NAME))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n\n            try\n            {\n                SystemKeyspace.checkHealth();\n            }\n            catch (ConfigurationException e)\n            {\n                throw new StartupException(StartupException.ERR_WRONG_CONFIG, \"Fatal exception during initialization\", e);\n            }\n        }\n    };\n\n    public static final StartupCheck checkDatacenter = new StartupCheck()\n    {\n        public void execute() throws StartupException\n        {\n            if (!Boolean.getBoolean(\"cassandra.ignore_dc\"))\n            {\n                String storedDc = SystemKeyspace.getDatacenter();\n                if (storedDc != null)\n                {\n                    String currentDc = DatabaseDescriptor.getEndpointSnitch().getLocalDatacenter();\n                    if (!storedDc.equals(currentDc))\n                    {\n                        String formatMessage = \"Cannot start node if snitch's data center (%s) differs from previous data center (%s). \" +\n                                               \"Please fix the snitch configuration, decommission and rebootstrap this node or use the flag -Dcassandra.ignore_dc=true.\";\n\n                        throw new StartupException(StartupException.ERR_WRONG_CONFIG, String.format(formatMessage, currentDc, storedDc));\n                    }\n                }\n            }\n        }\n    };\n\n    public static final StartupCheck checkRack = new StartupCheck()\n    {\n        public void execute() throws StartupException\n        {\n            if (!Boolean.getBoolean(\"cassandra.ignore_rack\"))\n            {\n                String storedRack = SystemKeyspace.getRack();\n                if (storedRack != null)\n                {\n                    String currentRack = DatabaseDescriptor.getEndpointSnitch().getLocalRack();\n                    if (!storedRack.equals(currentRack))\n                    {\n                        String formatMessage = \"Cannot start node if snitch's rack (%s) differs from previous rack (%s). \" +\n                                               \"Please fix the snitch configuration, decommission and rebootstrap this node or use the flag -Dcassandra.ignore_rack=true.\";\n\n                        throw new StartupException(StartupException.ERR_WRONG_CONFIG, String.format(formatMessage, currentRack, storedRack));\n                    }\n                }\n            }\n        }\n    };\n\n    public static final StartupCheck checkLegacyAuthTables = () ->\n    {\n        Optional<String> errMsg = checkLegacyAuthTablesMessage();\n        if (errMsg.isPresent())\n            throw new StartupException(StartupException.ERR_WRONG_CONFIG, errMsg.get());\n    };\n\n    @VisibleForTesting\n    static Optional<String> checkLegacyAuthTablesMessage()\n    {\n        List<String> existing = new ArrayList<>(SchemaConstants.LEGACY_AUTH_TABLES).stream().filter((legacyAuthTable) ->\n            {\n                UntypedResultSet result = QueryProcessor.executeOnceInternal(String.format(\"SELECT table_name FROM %s.%s WHERE keyspace_name='%s' AND table_name='%s'\",\n                                                                                           SchemaConstants.SCHEMA_KEYSPACE_NAME,\n                                                                                           \"tables\",\n                                                                                           SchemaConstants.AUTH_KEYSPACE_NAME,\n                                                                                           legacyAuthTable));\n                return result != null && !result.isEmpty();\n            }).collect(Collectors.toList());\n\n        if (!existing.isEmpty())\n            return Optional.of(String.format(\"Legacy auth tables %s in keyspace %s still exist and have not been properly migrated.\",\n                        Joiner.on(\", \").join(existing), SchemaConstants.AUTH_KEYSPACE_NAME));\n        else\n            return Optional.empty();\n    };\n}\n"
        },
        {
            "sender": "Developer Filter",
            "content": "Filter of the code context that is related to configuration: ```java\n@VisibleForTesting\nHintsService(IFailureDetector failureDetector)\n{\n    File hintsDirectory = DatabaseDescriptor.getHintsDirectory();\n    int maxDeliveryThreads = DatabaseDescriptor.getMaxHintsDeliveryThreads();\n\n    catalog = HintsCatalog.load(hintsDirectory, createDescriptorParams());\n    writeExecutor = new HintsWriteExecutor(catalog);\n\n    isDispatchPaused = new AtomicBoolean(true);\n    dispatchExecutor = new HintsDispatchExecutor(hintsDirectory, maxDeliveryThreads, isDispatchPaused, failureDetector::isAlive);\n\n    // periodically empty the current content of the buffers\n    int flushPeriod = DatabaseDescriptor.getHintsFlushPeriodInMS();\n    triggerFlushingFuture = ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(() -> writeExecutor.flushBufferPool(bufferPool),\n                                                                                    flushPeriod,\n                                                                                    flushPeriod,\n                                                                                    TimeUnit.MILLISECONDS);\n}\n```"
        },
        {
            "sender": "Developer summary",
            "content": "Summary of the extracted code context: ### Summary of Configuration: `hints_directory`\n\nThe `hints_directory` configuration plays a crucial role in the `HintsService` class, which is responsible for managing the delivery of hints in the system. Hints are used in distributed systems like Cassandra to ensure that writes to a node that is temporarily unavailable are eventually delivered once the node is back online.\n\n#### Purpose and Functionality:\n- **Storage Location**: The `hints_directory` specifies the file path where hint files are stored. This is essential for the system to retrieve and manage hints effectively.\n- **Initialization**: During the initialization of the `HintsService`, the `hintsDirectory` is obtained from the `DatabaseDescriptor.getHintsDirectory()` method. This establishes the directory for storing hints, ensuring that the service knows where to read and write hint data.\n- **Catalog Loading**: The `HintsCatalog` is loaded using the `hintsDirectory`, which allows the service to track and manage the hints that have been generated and need to be delivered.\n- **Dispatch Executor**: The `dispatchExecutor` is created with the `hintsDirectory` and is responsible for managing the delivery of hints. It uses the directory to access the hints that need to be dispatched to the appropriate nodes.\n\n#### Key Components and Dependencies:\n- **DatabaseDescriptor**: This class provides the configuration values, including the hints directory and the maximum number of delivery threads. It acts as a central source for configuration settings.\n- **HintsCatalog**: This component is responsible for loading and managing the hints stored in the `hints_directory`. It interacts closely with the `HintsService` to ensure that hints are processed correctly.\n- **HintsWriteExecutor**: This executor is tasked with writing hints to the catalog, utilizing the hints directory for storage.\n- **Scheduled Executors**: The service schedules periodic tasks to flush the buffer pool, ensuring that hints are regularly processed and delivered.\n\n#### Interaction with Other Parts of the System:\nThe `hints_directory` interacts with various components of the system, including:\n- **Failure Detection**: The `IFailureDetector` is used to check the health of nodes, ensuring that hints are only dispatched to nodes that are alive.\n- **Buffer Management**: The service manages a buffer pool for hints, which is periodically flushed to ensure timely delivery. This interaction is crucial for maintaining the integrity and reliability of the hint delivery process.\n\nIn summary, the `hints_directory` configuration is integral to the operation of the `HintsService`, facilitating the storage, management, and delivery of hints within the system. It serves as a critical point of interaction between various components responsible for ensuring data consistency in a distributed environment."
        },
        {
            "sender": "performance agent sensitivity",
            "content": "{\"Role\": \"You are a Performance Sensitivity Agent responsible for determining if a configuration is performance-sensitive within a software system.\", \"Requirement\": \"Using developer-provided information as a secondary reference, analyze the configuration-related code to determine if it is performance-sensitive. Focus exclusively on configurations with substantial system-level performance impact due to time-intensive or memory-intensive operations. Only configurations that directly cause significant performance variations through extremely time-consuming or memory-heavy operations should be classified as performance-sensitive. Minor or moderate impacts should not be considered.\", \"Output Format\": \"Respond strictly in one of the following formats: 'The configuration is Performance Sensitive: reason' or 'The configuration is Performance Insensitive: reason'. No other response format is acceptable. Provide a concise yet clear and detailed reason for your classification.\", \"configuration_name\": \"hints_directory\", \"code_context\": \"```java\\n@VisibleForTesting\\nHintsService(IFailureDetector failureDetector)\\n{\\n    File hintsDirectory = DatabaseDescriptor.getHintsDirectory();\\n    int maxDeliveryThreads = DatabaseDescriptor.getMaxHintsDeliveryThreads();\\n\\n    catalog = HintsCatalog.load(hintsDirectory, createDescriptorParams());\\n    writeExecutor = new HintsWriteExecutor(catalog);\\n\\n    isDispatchPaused = new AtomicBoolean(true);\\n    dispatchExecutor = new HintsDispatchExecutor(hintsDirectory, maxDeliveryThreads, isDispatchPaused, failureDetector::isAlive);\\n\\n    // periodically empty the current content of the buffers\\n    int flushPeriod = DatabaseDescriptor.getHintsFlushPeriodInMS();\\n    triggerFlushingFuture = ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(() -> writeExecutor.flushBufferPool(bufferPool),\\n                                                                                    flushPeriod,\\n                                                                                    flushPeriod,\\n                                                                                    TimeUnit.MILLISECONDS);\\n}\\n```\\n\\n--- Summary by Developer ---\\n### Summary of Configuration: `hints_directory`\\n\\nThe `hints_directory` configuration plays a crucial role in the `HintsService` class, which is responsible for managing the delivery of hints in the system. Hints are used in distributed systems like Cassandra to ensure that writes to a node that is temporarily unavailable are eventually delivered once the node is back online.\\n\\n#### Purpose and Functionality:\\n- **Storage Location**: The `hints_directory` specifies the file path where hint files are stored. This is essential for the system to retrieve and manage hints effectively.\\n- **Initialization**: During the initialization of the `HintsService`, the `hintsDirectory` is obtained from the `DatabaseDescriptor.getHintsDirectory()` method. This establishes the directory for storing hints, ensuring that the service knows where to read and write hint data.\\n- **Catalog Loading**: The `HintsCatalog` is loaded using the `hintsDirectory`, which allows the service to track and manage the hints that have been generated and need to be delivered.\\n- **Dispatch Executor**: The `dispatchExecutor` is created with the `hintsDirectory` and is responsible for managing the delivery of hints. It uses the directory to access the hints that need to be dispatched to the appropriate nodes.\\n\\n#### Key Components and Dependencies:\\n- **DatabaseDescriptor**: This class provides the configuration values, including the hints directory and the maximum number of delivery threads. It acts as a central source for configuration settings.\\n- **HintsCatalog**: This component is responsible for loading and managing the hints stored in the `hints_directory`. It interacts closely with the `HintsService` to ensure that hints are processed correctly.\\n- **HintsWriteExecutor**: This executor is tasked with writing hints to the catalog, utilizing the hints directory for storage.\\n- **Scheduled Executors**: The service schedules periodic tasks to flush the buffer pool, ensuring that hints are regularly processed and delivered.\\n\\n#### Interaction with Other Parts of the System:\\nThe `hints_directory` interacts with various components of the system, including:\\n- **Failure Detection**: The `IFailureDetector` is used to check the health of nodes, ensuring that hints are only dispatched to nodes that are alive.\\n- **Buffer Management**: The service manages a buffer pool for hints, which is periodically flushed to ensure timely delivery. This interaction is crucial for maintaining the integrity and reliability of the hint delivery process.\\n\\nIn summary, the `hints_directory` configuration is integral to the operation of the `HintsService`, facilitating the storage, management, and delivery of hints within the system. It serves as a critical point of interaction between various components responsible for ensuring data consistency in a distributed environment.\"}"
        },
        {
            "sender": "PerformanceSensitivity",
            "content": "The configuration is Performance Sensitive: The `hints_directory` is crucial for the storage and management of hints in a distributed system, directly impacting the performance of hint delivery operations. The loading of the `HintsCatalog` and the management of the `HintsWriteExecutor` rely on this configuration, which can lead to significant performance variations during time-intensive operations such as hint processing and buffer flushing. If the directory is not optimized or if there are issues with disk access, it can result in delays and increased memory usage, thereby affecting the overall system performance."
        }
    ]
}