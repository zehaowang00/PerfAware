{
    "performance_sensitive": "Yes",
    "config_name": "cdc_enabled",
    "messages": [
        {
            "sender": "System",
            "content": "Initialize the analysis for the target system and configuration."
        },
        {
            "sender": "Developer",
            "content": "public class DatabaseDescriptor\n{\n    static\n    {\n        // This static block covers most usages\n        FBUtilities.preventIllegalAccessWarnings();\n        System.setProperty(\"io.netty.transport.estimateSizeOnSubmit\", \"false\");\n    }\n\n    private static final Logger logger = LoggerFactory.getLogger(DatabaseDescriptor.class);\n\n    /**\n     * Tokens are serialized in a Gossip VersionedValue String.  VV are restricted to 64KB\n     * when we send them over the wire, which works out to about 1700 tokens.\n     */\n    private static final int MAX_NUM_TOKENS = 1536;\n\n    private static Config conf;\n\n    /**\n     * Request timeouts can not be less than below defined value (see CASSANDRA-9375)\n     */\n    static final long LOWEST_ACCEPTED_TIMEOUT = 10L;\n\n    private static IEndpointSnitch snitch;\n    private static InetAddress listenAddress; // leave null so we can fall through to getLocalHost\n    private static InetAddress broadcastAddress;\n    private static InetAddress rpcAddress;\n    private static InetAddress broadcastRpcAddress;\n    private static SeedProvider seedProvider;\n    private static IInternodeAuthenticator internodeAuthenticator = new AllowAllInternodeAuthenticator();\n\n    /* Hashing strategy Random or OPHF */\n    private static IPartitioner partitioner;\n    private static String paritionerName;\n\n    private static Config.DiskAccessMode indexAccessMode;\n\n    private static IAuthenticator authenticator;\n    private static IAuthorizer authorizer;\n    private static INetworkAuthorizer networkAuthorizer;\n    // Don't initialize the role manager until applying config. The options supported by CassandraRoleManager\n    // depend on the configured IAuthenticator, so defer creating it until that's been set.\n    private static IRoleManager roleManager;\n\n    private static long preparedStatementsCacheSizeInMB;\n\n    private static long keyCacheSizeInMB;\n    private static long counterCacheSizeInMB;\n    private static long indexSummaryCapacityInMB;\n\n    private static String localDC;\n    private static Comparator<Replica> localComparator;\n    private static EncryptionContext encryptionContext;\n    private static boolean hasLoggedConfig;\n\n    private static DiskOptimizationStrategy diskOptimizationStrategy;\n\n    private static boolean clientInitialized;\n    private static boolean toolInitialized;\n    private static boolean daemonInitialized;\n\n    private static final int searchConcurrencyFactor = Integer.parseInt(System.getProperty(Config.PROPERTY_PREFIX + \"search_concurrency_factor\", \"1\"));\n\n    private static volatile boolean disableSTCSInL0 = Boolean.getBoolean(Config.PROPERTY_PREFIX + \"disable_stcs_in_l0\");\n    private static final boolean unsafeSystem = Boolean.getBoolean(Config.PROPERTY_PREFIX + \"unsafesystem\");\n\n    // turns some warnings into exceptions for testing\n    private static final boolean strictRuntimeChecks = Boolean.getBoolean(\"cassandra.strict.runtime.checks\");\n\n    public static volatile boolean allowUnlimitedConcurrentValidations = Boolean.getBoolean(\"cassandra.allow_unlimited_concurrent_validations\");\n\n    private static Function<CommitLog, AbstractCommitLogSegmentManager> commitLogSegmentMgrProvider = c -> DatabaseDescriptor.isCDCEnabled()\n                                       ? new CommitLogSegmentManagerCDC(c, DatabaseDescriptor.getCommitLogLocation())\n                                       : new CommitLogSegmentManagerStandard(c, DatabaseDescriptor.getCommitLogLocation());\n\n    public static void daemonInitialization() throws ConfigurationException\n    {\n        daemonInitialization(DatabaseDescriptor::loadConfig);\n    }\n\n    public static void daemonInitialization(Supplier<Config> config) throws ConfigurationException\n    {\n        if (toolInitialized)\n            throw new AssertionError(\"toolInitialization() already called\");\n        if (clientInitialized)\n            throw new AssertionError(\"clientInitialization() already called\");\n\n        // Some unit tests require this :(\n        if (daemonInitialized)\n            return;\n        daemonInitialized = true;\n\n        setConfig(config.get());\n        applyAll();\n        AuthConfig.applyAuth();\n    }\n\n    /**\n     * Equivalent to {@link #toolInitialization(boolean) toolInitialization(true)}.\n     */\n    public static void toolInitialization()\n    {\n        toolInitialization(true);\n    }\n\n    /**\n     * Initializes this class as a tool, which means that the configuration is loaded\n     * using {@link #loadConfig()} and all non-daemon configuration parts will be setup.\n     *\n     * @param failIfDaemonOrClient if {@code true} and a call to {@link #daemonInitialization()} or\n     *                             {@link #clientInitialization()} has been performed before, an\n     *                             {@link AssertionError} will be thrown.\n     */\n    public static void toolInitialization(boolean failIfDaemonOrClient)\n    {\n        if (!failIfDaemonOrClient && (daemonInitialized || clientInitialized))\n        {\n            return;\n        }\n        else\n        {\n            if (daemonInitialized)\n                throw new AssertionError(\"daemonInitialization() already called\");\n            if (clientInitialized)\n                throw new AssertionError(\"clientInitialization() already called\");\n        }\n\n        if (toolInitialized)\n            return;\n        toolInitialized = true;\n\n        setConfig(loadConfig());\n\n        applySimpleConfig();\n\n        applyPartitioner();\n\n        applySnitch();\n\n        applyEncryptionContext();\n    }\n\n    /**\n     * Equivalent to {@link #clientInitialization(boolean) clientInitialization(true)}.\n     */\n    public static void clientInitialization()\n    {\n        clientInitialization(true);\n    }\n\n    /**\n     * Initializes this class as a client, which means that just an empty configuration will\n     * be used.\n     *\n     * @param failIfDaemonOrTool if {@code true} and a call to {@link #daemonInitialization()} or\n     *                           {@link #toolInitialization()} has been performed before, an\n     *                           {@link AssertionError} will be thrown.\n     */\n    public static void clientInitialization(boolean failIfDaemonOrTool)\n    {\n        if (!failIfDaemonOrTool && (daemonInitialized || toolInitialized))\n        {\n            return;\n        }\n        else\n        {\n            if (daemonInitialized)\n                throw new AssertionError(\"daemonInitialization() already called\");\n            if (toolInitialized)\n                throw new AssertionError(\"toolInitialization() already called\");\n        }\n\n        if (clientInitialized)\n            return;\n        clientInitialized = true;\n\n        Config.setClientMode(true);\n        conf = new Config();\n        diskOptimizationStrategy = new SpinningDiskOptimizationStrategy();\n    }\n\n    public static boolean isClientInitialized()\n    {\n        return clientInitialized;\n    }\n\n    public static boolean isToolInitialized()\n    {\n        return toolInitialized;\n    }\n\n    public static boolean isClientOrToolInitialized()\n    {\n        return clientInitialized || toolInitialized;\n    }\n\n    public static boolean isDaemonInitialized()\n    {\n        return daemonInitialized;\n    }\n\n    public static Config getRawConfig()\n    {\n        return conf;\n    }\n\n    @VisibleForTesting\n    public static Config loadConfig() throws ConfigurationException\n    {\n        if (Config.getOverrideLoadConfig() != null)\n            return Config.getOverrideLoadConfig().get();\n\n        String loaderClass = System.getProperty(Config.PROPERTY_PREFIX + \"config.loader\");\n        ConfigurationLoader loader = loaderClass == null\n                                     ? new YamlConfigurationLoader()\n                                     : FBUtilities.construct(loaderClass, \"configuration loading\");\n        Config config = loader.loadConfig();\n\n        if (!hasLoggedConfig)\n        {\n            hasLoggedConfig = true;\n            Config.log(config);\n        }\n\n        return config;\n    }\n\n    private static InetAddress getNetworkInterfaceAddress(String intf, String configName, boolean preferIPv6) throws ConfigurationException\n    {\n        try\n        {\n            NetworkInterface ni = NetworkInterface.getByName(intf);\n            if (ni == null)\n                throw new ConfigurationException(\"Configured \" + configName + \" \\\"\" + intf + \"\\\" could not be found\", false);\n            Enumeration<InetAddress> addrs = ni.getInetAddresses();\n            if (!addrs.hasMoreElements())\n                throw new ConfigurationException(\"Configured \" + configName + \" \\\"\" + intf + \"\\\" was found, but had no addresses\", false);\n\n            /*\n             * Try to return the first address of the preferred type, otherwise return the first address\n             */\n            InetAddress retval = null;\n            while (addrs.hasMoreElements())\n            {\n                InetAddress temp = addrs.nextElement();\n                if (preferIPv6 && temp instanceof Inet6Address) return temp;\n                if (!preferIPv6 && temp instanceof Inet4Address) return temp;\n                if (retval == null) retval = temp;\n            }\n            return retval;\n        }\n        catch (SocketException e)\n        {\n            throw new ConfigurationException(\"Configured \" + configName + \" \\\"\" + intf + \"\\\" caused an exception\", e);\n        }\n    }\n\n    private static void setConfig(Config config)\n    {\n        conf = config;\n    }\n\n    private static void applyAll() throws ConfigurationException\n    {\n        //InetAddressAndPort cares that applySimpleConfig runs first\n        applySimpleConfig();\n\n        applyPartitioner();\n\n        applyAddressConfig();\n\n        applySnitch();\n\n        applyTokensConfig();\n\n        applySeedProvider();\n\n        applyEncryptionContext();\n\n        applySslContext();\n    }\n\n    private static void applySimpleConfig()\n    {\n        //Doing this first before all other things in case other pieces of config want to construct\n        //InetAddressAndPort and get the right defaults\n        InetAddressAndPort.initializeDefaultPort(getStoragePort());\n\n        if (conf.commitlog_sync == null)\n        {\n            throw new ConfigurationException(\"Missing required directive CommitLogSync\", false);\n        }\n\n        if (conf.commitlog_sync == Config.CommitLogSync.batch)\n        {\n            if (conf.commitlog_sync_period_in_ms != 0)\n            {\n                throw new ConfigurationException(\"Batch sync specified, but commitlog_sync_period_in_ms found. Only specify commitlog_sync_batch_window_in_ms when using batch sync\", false);\n            }\n            logger.debug(\"Syncing log with batch mode\");\n        }\n        else if (conf.commitlog_sync == CommitLogSync.group)\n        {\n            if (Double.isNaN(conf.commitlog_sync_group_window_in_ms) || conf.commitlog_sync_group_window_in_ms <= 0d)\n            {\n                throw new ConfigurationException(\"Missing value for commitlog_sync_group_window_in_ms: positive double value expected.\", false);\n            }\n            else if (conf.commitlog_sync_period_in_ms != 0)\n            {\n                throw new ConfigurationException(\"Group sync specified, but commitlog_sync_period_in_ms found. Only specify commitlog_sync_group_window_in_ms when using group sync\", false);\n            }\n            logger.debug(\"Syncing log with a group window of {}\", conf.commitlog_sync_period_in_ms);\n        }\n        else\n        {\n            if (conf.commitlog_sync_period_in_ms <= 0)\n            {\n                throw new ConfigurationException(\"Missing value for commitlog_sync_period_in_ms: positive integer expected\", false);\n            }\n            else if (!Double.isNaN(conf.commitlog_sync_batch_window_in_ms))\n            {\n                throw new ConfigurationException(\"commitlog_sync_period_in_ms specified, but commitlog_sync_batch_window_in_ms found.  Only specify commitlog_sync_period_in_ms when using periodic sync.\", false);\n            }\n            logger.debug(\"Syncing log with a period of {}\", conf.commitlog_sync_period_in_ms);\n        }\n\n        /* evaluate the DiskAccessMode Config directive, which also affects indexAccessMode selection */\n        if (conf.disk_access_mode == Config.DiskAccessMode.auto)\n        {\n            conf.disk_access_mode = hasLargeAddressSpace() ? Config.DiskAccessMode.mmap : Config.DiskAccessMode.standard;\n            indexAccessMode = conf.disk_access_mode;\n            logger.info(\"DiskAccessMode 'auto' determined to be {}, indexAccessMode is {}\", conf.disk_access_mode, indexAccessMode);\n        }\n        else if (conf.disk_access_mode == Config.DiskAccessMode.mmap_index_only)\n        {\n            conf.disk_access_mode = Config.DiskAccessMode.standard;\n            indexAccessMode = Config.DiskAccessMode.mmap;\n            logger.info(\"DiskAccessMode is {}, indexAccessMode is {}\", conf.disk_access_mode, indexAccessMode);\n        }\n        else\n        {\n            indexAccessMode = conf.disk_access_mode;\n            logger.info(\"DiskAccessMode is {}, indexAccessMode is {}\", conf.disk_access_mode, indexAccessMode);\n        }\n\n        if (conf.gc_warn_threshold_in_ms < 0)\n        {\n            throw new ConfigurationException(\"gc_warn_threshold_in_ms must be a positive integer\");\n        }\n\n        /* phi convict threshold for FailureDetector */\n        if (conf.phi_convict_threshold < 5 || conf.phi_convict_threshold > 16)\n        {\n            throw new ConfigurationException(\"phi_convict_threshold must be between 5 and 16, but was \" + conf.phi_convict_threshold, false);\n        }\n\n        /* Thread per pool */\n        if (conf.concurrent_reads < 2)\n        {\n            throw new ConfigurationException(\"concurrent_reads must be at least 2, but was \" + conf.concurrent_reads, false);\n        }\n\n        if (conf.concurrent_writes < 2 && System.getProperty(\"cassandra.test.fail_mv_locks_count\", \"\").isEmpty())\n        {\n            throw new ConfigurationException(\"concurrent_writes must be at least 2, but was \" + conf.concurrent_writes, false);\n        }\n\n        if (conf.concurrent_counter_writes < 2)\n            throw new ConfigurationException(\"concurrent_counter_writes must be at least 2, but was \" + conf.concurrent_counter_writes, false);\n\n        if (conf.concurrent_replicates != null)\n            logger.warn(\"concurrent_replicates has been deprecated and should be removed from cassandra.yaml\");\n\n        if (conf.networking_cache_size_in_mb == null)\n            conf.networking_cache_size_in_mb = Math.min(128, (int) (Runtime.getRuntime().maxMemory() / (16 * 1048576)));\n\n        if (conf.file_cache_size_in_mb == null)\n            conf.file_cache_size_in_mb = Math.min(512, (int) (Runtime.getRuntime().maxMemory() / (4 * 1048576)));\n\n        // round down for SSDs and round up for spinning disks\n        if (conf.file_cache_round_up == null)\n            conf.file_cache_round_up = conf.disk_optimization_strategy == Config.DiskOptimizationStrategy.spinning;\n\n        if (conf.memtable_offheap_space_in_mb == null)\n            conf.memtable_offheap_space_in_mb = (int) (Runtime.getRuntime().maxMemory() / (4 * 1048576));\n        if (conf.memtable_offheap_space_in_mb < 0)\n            throw new ConfigurationException(\"memtable_offheap_space_in_mb must be positive, but was \" + conf.memtable_offheap_space_in_mb, false);\n        // for the moment, we default to twice as much on-heap space as off-heap, as heap overhead is very large\n        if (conf.memtable_heap_space_in_mb == null)\n            conf.memtable_heap_space_in_mb = (int) (Runtime.getRuntime().maxMemory() / (4 * 1048576));\n        if (conf.memtable_heap_space_in_mb <= 0)\n            throw new ConfigurationException(\"memtable_heap_space_in_mb must be positive, but was \" + conf.memtable_heap_space_in_mb, false);\n        logger.info(\"Global memtable on-heap threshold is enabled at {}MB\", conf.memtable_heap_space_in_mb);\n        if (conf.memtable_offheap_space_in_mb == 0)\n            logger.info(\"Global memtable off-heap threshold is disabled, HeapAllocator will be used instead\");\n        else\n            logger.info(\"Global memtable off-heap threshold is enabled at {}MB\", conf.memtable_offheap_space_in_mb);\n\n        if (conf.repair_session_max_tree_depth != null)\n        {\n            logger.warn(\"repair_session_max_tree_depth has been deprecated and should be removed from cassandra.yaml. Use repair_session_space_in_mb instead\");\n            if (conf.repair_session_max_tree_depth < 10)\n                throw new ConfigurationException(\"repair_session_max_tree_depth should not be < 10, but was \" + conf.repair_session_max_tree_depth);\n            if (conf.repair_session_max_tree_depth > 20)\n                logger.warn(\"repair_session_max_tree_depth of \" + conf.repair_session_max_tree_depth + \" > 20 could lead to excessive memory usage\");\n        }\n        else\n        {\n            conf.repair_session_max_tree_depth = 20;\n        }\n\n        if (conf.repair_session_space_in_mb == null)\n            conf.repair_session_space_in_mb = Math.max(1, (int) (Runtime.getRuntime().maxMemory() / (16 * 1048576)));\n\n        if (conf.repair_session_space_in_mb < 1)\n            throw new ConfigurationException(\"repair_session_space_in_mb must be > 0, but was \" + conf.repair_session_space_in_mb);\n        else if (conf.repair_session_space_in_mb > (int) (Runtime.getRuntime().maxMemory() / (4 * 1048576)))\n            logger.warn(\"A repair_session_space_in_mb of \" + conf.repair_session_space_in_mb + \" megabytes is likely to cause heap pressure\");\n\n        checkForLowestAcceptedTimeouts(conf);\n\n        checkValidForByteConversion(conf.native_transport_max_frame_size_in_mb,\n                                    \"native_transport_max_frame_size_in_mb\", ByteUnit.MEBI_BYTES);\n\n        checkValidForByteConversion(conf.column_index_size_in_kb,\n                                    \"column_index_size_in_kb\", ByteUnit.KIBI_BYTES);\n\n        checkValidForByteConversion(conf.column_index_cache_size_in_kb,\n                                    \"column_index_cache_size_in_kb\", ByteUnit.KIBI_BYTES);\n\n        checkValidForByteConversion(conf.batch_size_warn_threshold_in_kb,\n                                    \"batch_size_warn_threshold_in_kb\", ByteUnit.KIBI_BYTES);\n\n        if (conf.native_transport_max_negotiable_protocol_version != null)\n            logger.warn(\"The configuration option native_transport_max_negotiable_protocol_version has been deprecated \" +\n                        \"and should be removed from cassandra.yaml as it has no longer has any effect.\");\n\n        // if data dirs, commitlog dir, or saved caches dir are set in cassandra.yaml, use that.  Otherwise,\n        // use -Dcassandra.storagedir (set in cassandra-env.sh) as the parent dir for data/, commitlog/, and saved_caches/\n        if (conf.commitlog_directory == null)\n        {\n            conf.commitlog_directory = storagedirFor(\"commitlog\");\n        }\n\n        if (conf.hints_directory == null)\n        {\n            conf.hints_directory = storagedirFor(\"hints\");\n        }\n\n        if (conf.native_transport_max_concurrent_requests_in_bytes <= 0)\n        {\n            conf.native_transport_max_concurrent_requests_in_bytes = Runtime.getRuntime().maxMemory() / 10;\n        }\n\n        if (conf.native_transport_max_concurrent_requests_in_bytes_per_ip <= 0)\n        {\n            conf.native_transport_max_concurrent_requests_in_bytes_per_ip = Runtime.getRuntime().maxMemory() / 40;\n        }\n\n        if (conf.commitlog_total_space_in_mb == null)\n        {\n            final int preferredSizeInMB = 8192;\n            try\n            {\n                // use 1/4 of available space.  See discussion on #10013 and #10199\n                final long totalSpaceInBytes = guessFileStore(conf.commitlog_directory).getTotalSpace();\n                conf.commitlog_total_space_in_mb = calculateDefaultSpaceInMB(\"commitlog\",\n                                                                             conf.commitlog_directory,\n                                                                             \"commitlog_total_space_in_mb\",\n                                                                             preferredSizeInMB,\n                                                                             totalSpaceInBytes, 1, 4);\n\n            }\n            catch (IOException e)\n            {\n                logger.debug(\"Error checking disk space\", e);\n                throw new ConfigurationException(String.format(\"Unable to check disk space available to '%s'. Perhaps the Cassandra user does not have the necessary permissions\",\n                                                               conf.commitlog_directory), e);\n            }\n        }\n\n        if (conf.cdc_enabled)\n        {\n            // Windows memory-mapped CommitLog files is incompatible with CDC as we hard-link files in cdc_raw. Confirm we don't have both enabled.\n            if (FBUtilities.isWindows && conf.commitlog_compression == null)\n                throw new ConfigurationException(\"Cannot enable cdc on Windows with uncompressed commitlog.\");\n\n            if (conf.cdc_raw_directory == null)\n            {\n                conf.cdc_raw_directory = storagedirFor(\"cdc_raw\");\n            }\n\n            if (conf.cdc_total_space_in_mb == 0)\n            {\n                final int preferredSizeInMB = 4096;\n                try\n                {\n                    // use 1/8th of available space.  See discussion on #10013 and #10199 on the CL, taking half that for CDC\n                    final long totalSpaceInBytes = guessFileStore(conf.cdc_raw_directory).getTotalSpace();\n                    conf.cdc_total_space_in_mb = calculateDefaultSpaceInMB(\"cdc\",\n                                                                           conf.cdc_raw_directory,\n                                                                           \"cdc_total_space_in_mb\",\n                                                                           preferredSizeInMB,\n                                                                           totalSpaceInBytes, 1, 8);\n                }\n                catch (IOException e)\n                {\n                    logger.debug(\"Error checking disk space\", e);\n                    throw new ConfigurationException(String.format(\"Unable to check disk space available to '%s'. Perhaps the Cassandra user does not have the necessary permissions\",\n                                                                   conf.cdc_raw_directory), e);\n                }\n            }\n\n            logger.info(\"cdc_enabled is true. Starting casssandra node with Change-Data-Capture enabled.\");\n        }\n\n        if (conf.saved_caches_directory == null)\n        {\n            conf.saved_caches_directory = storagedirFor(\"saved_caches\");\n        }\n        if (conf.data_file_directories == null || conf.data_file_directories.length == 0)\n        {\n            conf.data_file_directories = new String[]{ storagedir(\"data_file_directories\") + File.separator + \"data\" };\n        }\n\n        long dataFreeBytes = 0;\n        /* data file and commit log directories. they get created later, when they're needed. */\n        for (String datadir : conf.data_file_directories)\n        {\n            if (datadir == null)\n                throw new ConfigurationException(\"data_file_directories must not contain empty entry\", false);\n            if (datadir.equals(conf.local_system_data_file_directory))\n                throw new ConfigurationException(\"local_system_data_file_directory must not be the same as any data_file_directories\", false);\n            if (datadir.equals(conf.commitlog_directory))\n                throw new ConfigurationException(\"commitlog_directory must not be the same as any data_file_directories\", false);\n            if (datadir.equals(conf.hints_directory))\n                throw new ConfigurationException(\"hints_directory must not be the same as any data_file_directories\", false);\n            if (datadir.equals(conf.saved_caches_directory))\n                throw new ConfigurationException(\"saved_caches_directory must not be the same as any data_file_directories\", false);\n\n            dataFreeBytes = saturatedSum(dataFreeBytes, getUnallocatedSpace(datadir));\n        }\n        if (dataFreeBytes < 64 * ONE_GB) // 64 GB\n            logger.warn(\"Only {} free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots\",\n                        FBUtilities.prettyPrintMemory(dataFreeBytes));\n\n        if (conf.local_system_data_file_directory != null)\n        {\n            if (conf.local_system_data_file_directory.equals(conf.commitlog_directory))\n                throw new ConfigurationException(\"local_system_data_file_directory must not be the same as the commitlog_directory\", false);\n            if (conf.local_system_data_file_directory.equals(conf.saved_caches_directory))\n                throw new ConfigurationException(\"local_system_data_file_directory must not be the same as the saved_caches_directory\", false);\n            if (conf.local_system_data_file_directory.equals(conf.hints_directory))\n                throw new ConfigurationException(\"local_system_data_file_directory must not be the same as the hints_directory\", false);\n\n            long freeBytes = getUnallocatedSpace(conf.local_system_data_file_directory);\n\n            if (freeBytes < ONE_GB)\n                logger.warn(\"Only {} free in the system data volume. Consider adding more capacity or removing obsolete snapshots\",\n                            FBUtilities.prettyPrintMemory(freeBytes));\n        }\n\n        if (conf.commitlog_directory.equals(conf.saved_caches_directory))\n            throw new ConfigurationException(\"saved_caches_directory must not be the same as the commitlog_directory\", false);\n        if (conf.commitlog_directory.equals(conf.hints_directory))\n            throw new ConfigurationException(\"hints_directory must not be the same as the commitlog_directory\", false);\n        if (conf.hints_directory.equals(conf.saved_caches_directory))\n            throw new ConfigurationException(\"saved_caches_directory must not be the same as the hints_directory\", false);\n\n        if (conf.memtable_flush_writers == 0)\n        {\n            conf.memtable_flush_writers = conf.data_file_directories.length == 1 ? 2 : 1;\n        }\n\n        if (conf.memtable_flush_writers < 1)\n            throw new ConfigurationException(\"memtable_flush_writers must be at least 1, but was \" + conf.memtable_flush_writers, false);\n\n        if (conf.memtable_cleanup_threshold == null)\n        {\n            conf.memtable_cleanup_threshold = (float) (1.0 / (1 + conf.memtable_flush_writers));\n        }\n        else\n        {\n            logger.warn(\"memtable_cleanup_threshold has been deprecated and should be removed from cassandra.yaml\");\n        }\n\n        if (conf.memtable_cleanup_threshold < 0.01f)\n            throw new ConfigurationException(\"memtable_cleanup_threshold must be >= 0.01, but was \" + conf.memtable_cleanup_threshold, false);\n        if (conf.memtable_cleanup_threshold > 0.99f)\n            throw new ConfigurationException(\"memtable_cleanup_threshold must be <= 0.99, but was \" + conf.memtable_cleanup_threshold, false);\n        if (conf.memtable_cleanup_threshold < 0.1f)\n            logger.warn(\"memtable_cleanup_threshold is set very low [{}], which may cause performance degradation\", conf.memtable_cleanup_threshold);\n\n        if (conf.concurrent_compactors == null)\n            conf.concurrent_compactors = Math.min(8, Math.max(2, Math.min(FBUtilities.getAvailableProcessors(), conf.data_file_directories.length)));\n\n        if (conf.concurrent_compactors <= 0)\n            throw new ConfigurationException(\"concurrent_compactors should be strictly greater than 0, but was \" + conf.concurrent_compactors, false);\n\n        applyConcurrentValidations(conf);\n        applyRepairCommandPoolSize(conf);\n\n        if (conf.concurrent_materialized_view_builders <= 0)\n            throw new ConfigurationException(\"concurrent_materialized_view_builders should be strictly greater than 0, but was \" + conf.concurrent_materialized_view_builders, false);\n\n        if (conf.num_tokens != null && conf.num_tokens > MAX_NUM_TOKENS)\n            throw new ConfigurationException(String.format(\"A maximum number of %d tokens per node is supported\", MAX_NUM_TOKENS), false);\n\n        try\n        {\n            // if prepared_statements_cache_size_mb option was set to \"auto\" then size of the cache should be \"max(1/256 of Heap (in MB), 10MB)\"\n            preparedStatementsCacheSizeInMB = (conf.prepared_statements_cache_size_mb == null)\n                                              ? Math.max(10, (int) (Runtime.getRuntime().maxMemory() / 1024 / 1024 / 256))\n                                              : conf.prepared_statements_cache_size_mb;\n\n            if (preparedStatementsCacheSizeInMB <= 0)\n                throw new NumberFormatException(); // to escape duplicating error message\n        }\n        catch (NumberFormatException e)\n        {\n            throw new ConfigurationException(\"prepared_statements_cache_size_mb option was set incorrectly to '\"\n                                             + conf.prepared_statements_cache_size_mb + \"', supported values are <integer> >= 0.\", false);\n        }\n\n        try\n        {\n            // if key_cache_size_in_mb option was set to \"auto\" then size of the cache should be \"min(5% of Heap (in MB), 100MB)\n            keyCacheSizeInMB = (conf.key_cache_size_in_mb == null)\n                               ? Math.min(Math.max(1, (int) (Runtime.getRuntime().totalMemory() * 0.05 / 1024 / 1024)), 100)\n                               : conf.key_cache_size_in_mb;\n\n            if (keyCacheSizeInMB < 0)\n                throw new NumberFormatException(); // to escape duplicating error message\n        }\n        catch (NumberFormatException e)\n        {\n            throw new ConfigurationException(\"key_cache_size_in_mb option was set incorrectly to '\"\n                                             + conf.key_cache_size_in_mb + \"', supported values are <integer> >= 0.\", false);\n        }\n\n        try\n        {\n            // if counter_cache_size_in_mb option was set to \"auto\" then size of the cache should be \"min(2.5% of Heap (in MB), 50MB)\n            counterCacheSizeInMB = (conf.counter_cache_size_in_mb == null)\n                                   ? Math.min(Math.max(1, (int) (Runtime.getRuntime().totalMemory() * 0.025 / 1024 / 1024)), 50)\n                                   : conf.counter_cache_size_in_mb;\n\n            if (counterCacheSizeInMB < 0)\n                throw new NumberFormatException(); // to escape duplicating error message\n        }\n        catch (NumberFormatException e)\n        {\n            throw new ConfigurationException(\"counter_cache_size_in_mb option was set incorrectly to '\"\n                                             + conf.counter_cache_size_in_mb + \"', supported values are <integer> >= 0.\", false);\n        }\n\n        // if set to empty/\"auto\" then use 5% of Heap size\n        indexSummaryCapacityInMB = (conf.index_summary_capacity_in_mb == null)\n                                   ? Math.max(1, (int) (Runtime.getRuntime().totalMemory() * 0.05 / 1024 / 1024))\n                                   : conf.index_summary_capacity_in_mb;\n\n        if (indexSummaryCapacityInMB < 0)\n            throw new ConfigurationException(\"index_summary_capacity_in_mb option was set incorrectly to '\"\n                                             + conf.index_summary_capacity_in_mb + \"', it should be a non-negative integer.\", false);\n\n        if (conf.user_defined_function_fail_timeout < 0)\n            throw new ConfigurationException(\"user_defined_function_fail_timeout must not be negative\", false);\n        if (conf.user_defined_function_warn_timeout < 0)\n            throw new ConfigurationException(\"user_defined_function_warn_timeout must not be negative\", false);\n\n        if (conf.user_defined_function_fail_timeout < conf.user_defined_function_warn_timeout)\n            throw new ConfigurationException(\"user_defined_function_warn_timeout must less than user_defined_function_fail_timeout\", false);\n\n        if (!conf.allow_insecure_udfs && !conf.enable_user_defined_functions_threads)\n            throw new ConfigurationException(\"To be able to set enable_user_defined_functions_threads: false you need to set allow_insecure_udfs: true - this is an unsafe configuration and is not recommended.\");\n\n        if (conf.allow_extra_insecure_udfs)\n            logger.warn(\"Allowing java.lang.System.* access in UDFs is dangerous and not recommended. Set allow_extra_insecure_udfs: false to disable.\");\n\n        if(conf.enable_scripted_user_defined_functions)\n            logger.warn(\"JavaScript user-defined functions have been deprecated. You can still use them but the plan is to remove them in the next major version. For more information - CASSANDRA-17280\");\n\n        if (conf.commitlog_segment_size_in_mb <= 0)\n            throw new ConfigurationException(\"commitlog_segment_size_in_mb must be positive, but was \"\n                    + conf.commitlog_segment_size_in_mb, false);\n        else if (conf.commitlog_segment_size_in_mb >= 2048)\n            throw new ConfigurationException(\"commitlog_segment_size_in_mb must be smaller than 2048, but was \"\n                    + conf.commitlog_segment_size_in_mb, false);\n\n        if (conf.max_mutation_size_in_kb == null)\n            conf.max_mutation_size_in_kb = conf.commitlog_segment_size_in_mb * 1024 / 2;\n        else if (conf.commitlog_segment_size_in_mb * 1024 < 2 * conf.max_mutation_size_in_kb)\n            throw new ConfigurationException(\"commitlog_segment_size_in_mb must be at least twice the size of max_mutation_size_in_kb / 1024\", false);\n\n        // native transport encryption options\n        if (conf.client_encryption_options != null)\n        {\n            conf.client_encryption_options.applyConfig();\n\n            if (conf.native_transport_port_ssl != null\n                && conf.native_transport_port_ssl != conf.native_transport_port\n                && conf.client_encryption_options.tlsEncryptionPolicy() == EncryptionOptions.TlsEncryptionPolicy.UNENCRYPTED)\n            {\n                throw new ConfigurationException(\"Encryption must be enabled in client_encryption_options for native_transport_port_ssl\", false);\n            }\n        }\n\n        if (conf.snapshot_links_per_second < 0)\n            throw new ConfigurationException(\"snapshot_links_per_second must be >= 0\");\n\n        if (conf.max_value_size_in_mb <= 0)\n            throw new ConfigurationException(\"max_value_size_in_mb must be positive\", false);\n        else if (conf.max_value_size_in_mb >= 2048)\n            throw new ConfigurationException(\"max_value_size_in_mb must be smaller than 2048, but was \"\n                    + conf.max_value_size_in_mb, false);\n\n        switch (conf.disk_optimization_strategy)\n        {\n            case ssd:\n                diskOptimizationStrategy = new SsdDiskOptimizationStrategy(conf.disk_optimization_page_cross_chance);\n                break;\n            case spinning:\n                diskOptimizationStrategy = new SpinningDiskOptimizationStrategy();\n                break;\n        }\n\n        if (conf.server_encryption_options != null)\n        {\n            conf.server_encryption_options.applyConfig();\n\n            if (conf.server_encryption_options.enable_legacy_ssl_storage_port &&\n                conf.server_encryption_options.tlsEncryptionPolicy() == EncryptionOptions.TlsEncryptionPolicy.UNENCRYPTED)\n            {\n                throw new ConfigurationException(\"enable_legacy_ssl_storage_port is true (enabled) with internode encryption disabled (none). Enable encryption or disable the legacy ssl storage port.\");\n            }\n        }\n        Integer maxMessageSize = conf.internode_max_message_size_in_bytes;\n        if (maxMessageSize != null)\n        {\n            if (maxMessageSize > conf.internode_application_receive_queue_reserve_endpoint_capacity_in_bytes)\n                throw new ConfigurationException(\"internode_max_message_size_in_mb must no exceed internode_application_receive_queue_reserve_endpoint_capacity_in_bytes\", false);\n\n            if (maxMessageSize > conf.internode_application_receive_queue_reserve_global_capacity_in_bytes)\n                throw new ConfigurationException(\"internode_max_message_size_in_mb must no exceed internode_application_receive_queue_reserve_global_capacity_in_bytes\", false);\n\n            if (maxMessageSize > conf.internode_application_send_queue_reserve_endpoint_capacity_in_bytes)\n                throw new ConfigurationException(\"internode_max_message_size_in_mb must no exceed internode_application_send_queue_reserve_endpoint_capacity_in_bytes\", false);\n\n            if (maxMessageSize > conf.internode_application_send_queue_reserve_global_capacity_in_bytes)\n                throw new ConfigurationException(\"internode_max_message_size_in_mb must no exceed internode_application_send_queue_reserve_global_capacity_in_bytes\", false);\n        }\n        else\n        {\n            conf.internode_max_message_size_in_bytes =\n                Math.min(conf.internode_application_receive_queue_reserve_endpoint_capacity_in_bytes,\n                         conf.internode_application_send_queue_reserve_endpoint_capacity_in_bytes);\n        }\n\n        validateMaxConcurrentAutoUpgradeTasksConf(conf.max_concurrent_automatic_sstable_upgrades);\n    }\n\n    @VisibleForTesting\n    static void applyConcurrentValidations(Config config)\n    {\n        if (config.concurrent_validations < 1)\n        {\n            config.concurrent_validations = config.concurrent_compactors;\n        }\n        else if (config.concurrent_validations > config.concurrent_compactors && !allowUnlimitedConcurrentValidations)\n        {\n            throw new ConfigurationException(\"To set concurrent_validations > concurrent_compactors, \" +\n                                             \"set the system property cassandra.allow_unlimited_concurrent_validations=true\");\n        }\n    }\n\n    @VisibleForTesting\n    static void applyRepairCommandPoolSize(Config config)\n    {\n        if (config.repair_command_pool_size < 1)\n            config.repair_command_pool_size = config.concurrent_validations;\n    }\n\n    private static String storagedirFor(String type)\n    {\n        return storagedir(type + \"_directory\") + File.separator + type;\n    }\n\n    private static String storagedir(String errMsgType)\n    {\n        String storagedir = System.getProperty(Config.PROPERTY_PREFIX + \"storagedir\", null);\n        if (storagedir == null)\n            throw new ConfigurationException(errMsgType + \" is missing and -Dcassandra.storagedir is not set\", false);\n        return storagedir;\n    }\n\n    static int calculateDefaultSpaceInMB(String type, String path, String setting, int preferredSizeInMB, long totalSpaceInBytes, long totalSpaceNumerator, long totalSpaceDenominator)\n    {\n        final long totalSizeInMB = totalSpaceInBytes / ONE_MB;\n        final int minSizeInMB = Ints.saturatedCast(totalSpaceNumerator * totalSizeInMB / totalSpaceDenominator);\n\n        if (minSizeInMB < preferredSizeInMB)\n        {\n            logger.warn(\"Small {} volume detected at '{}'; setting {} to {}.  You can override this in cassandra.yaml\",\n                        type, path, setting, minSizeInMB);\n            return minSizeInMB;\n        }\n        else\n        {\n            return preferredSizeInMB;\n        }\n    }\n\n    public static void applyAddressConfig() throws ConfigurationException\n    {\n        applyAddressConfig(conf);\n    }\n\n    public static void applyAddressConfig(Config config) throws ConfigurationException\n    {\n        listenAddress = null;\n        rpcAddress = null;\n        broadcastAddress = null;\n        broadcastRpcAddress = null;\n\n        /* Local IP, hostname or interface to bind services to */\n        if (config.listen_address != null && config.listen_interface != null)\n        {\n            throw new ConfigurationException(\"Set listen_address OR listen_interface, not both\", false);\n        }\n        else if (config.listen_address != null)\n        {\n            try\n            {\n                listenAddress = InetAddress.getByName(config.listen_address);\n            }\n            catch (UnknownHostException e)\n            {\n                throw new ConfigurationException(\"Unknown listen_address '\" + config.listen_address + '\\'', false);\n            }\n\n            if (listenAddress.isAnyLocalAddress())\n                throw new ConfigurationException(\"listen_address cannot be a wildcard address (\" + config.listen_address + \")!\", false);\n        }\n        else if (config.listen_interface != null)\n        {\n            listenAddress = getNetworkInterfaceAddress(config.listen_interface, \"listen_interface\", config.listen_interface_prefer_ipv6);\n        }\n\n        /* Gossip Address to broadcast */\n        if (config.broadcast_address != null)\n        {\n            try\n            {\n                broadcastAddress = InetAddress.getByName(config.broadcast_address);\n            }\n            catch (UnknownHostException e)\n            {\n                throw new ConfigurationException(\"Unknown broadcast_address '\" + config.broadcast_address + '\\'', false);\n            }\n\n            if (broadcastAddress.isAnyLocalAddress())\n                throw new ConfigurationException(\"broadcast_address cannot be a wildcard address (\" + config.broadcast_address + \")!\", false);\n        }\n\n        /* Local IP, hostname or interface to bind RPC server to */\n        if (config.rpc_address != null && config.rpc_interface != null)\n        {\n            throw new ConfigurationException(\"Set rpc_address OR rpc_interface, not both\", false);\n        }\n        else if (config.rpc_address != null)\n        {\n            try\n            {\n                rpcAddress = InetAddress.getByName(config.rpc_address);\n            }\n            catch (UnknownHostException e)\n            {\n                throw new ConfigurationException(\"Unknown host in rpc_address \" + config.rpc_address, false);\n            }\n        }\n        else if (config.rpc_interface != null)\n        {\n            rpcAddress = getNetworkInterfaceAddress(config.rpc_interface, \"rpc_interface\", config.rpc_interface_prefer_ipv6);\n        }\n        else\n        {\n            rpcAddress = FBUtilities.getJustLocalAddress();\n        }\n\n        /* RPC address to broadcast */\n        if (config.broadcast_rpc_address != null)\n        {\n            try\n            {\n                broadcastRpcAddress = InetAddress.getByName(config.broadcast_rpc_address);\n            }\n            catch (UnknownHostException e)\n            {\n                throw new ConfigurationException(\"Unknown broadcast_rpc_address '\" + config.broadcast_rpc_address + '\\'', false);\n            }\n\n            if (broadcastRpcAddress.isAnyLocalAddress())\n                throw new ConfigurationException(\"broadcast_rpc_address cannot be a wildcard address (\" + config.broadcast_rpc_address + \")!\", false);\n        }\n        else\n        {\n            if (rpcAddress.isAnyLocalAddress())\n                throw new ConfigurationException(\"If rpc_address is set to a wildcard address (\" + config.rpc_address + \"), then \" +\n                                                 \"you must set broadcast_rpc_address to a value other than \" + config.rpc_address, false);\n        }\n    }\n\n    public static void applyEncryptionContext()\n    {\n        // always attempt to load the cipher factory, as we could be in the situation where the user has disabled encryption,\n        // but has existing commitlogs and sstables on disk that are still encrypted (and still need to be read)\n        encryptionContext = new EncryptionContext(conf.transparent_data_encryption_options);\n    }\n\n    public static void applySslContext()\n    {\n        try\n        {\n            SSLFactory.validateSslContext(\"Internode messaging\", conf.server_encryption_options, true, true);\n            SSLFactory.validateSslContext(\"Native transport\", conf.client_encryption_options, conf.client_encryption_options.require_client_auth, true);\n            SSLFactory.initHotReloading(conf.server_encryption_options, conf.client_encryption_options, false);\n        }\n        catch (IOException e)\n        {\n            throw new ConfigurationException(\"Failed to initialize SSL\", e);\n        }\n    }\n\n    public static void applySeedProvider()\n    {\n        // load the seeds for node contact points\n        if (conf.seed_provider == null)\n        {\n            throw new ConfigurationException(\"seeds configuration is missing; a minimum of one seed is required.\", false);\n        }\n        try\n        {\n            Class<?> seedProviderClass = Class.forName(conf.seed_provider.class_name);\n            seedProvider = (SeedProvider)seedProviderClass.getConstructor(Map.class).newInstance(conf.seed_provider.parameters);\n        }\n        // there are about 5 checked exceptions that could be thrown here.\n        catch (Exception e)\n        {\n            throw new ConfigurationException(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\", true);\n        }\n        if (seedProvider.getSeeds().size() == 0)\n            throw new ConfigurationException(\"The seed provider lists no seeds.\", false);\n    }\n\n    @VisibleForTesting\n    static void checkForLowestAcceptedTimeouts(Config conf)\n    {\n        if(conf.read_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"read_request_timeout_in_ms\", conf.read_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.read_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.range_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"range_request_timeout_in_ms\", conf.range_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.range_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"request_timeout_in_ms\", conf.request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.write_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"write_request_timeout_in_ms\", conf.write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.cas_contention_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"cas_contention_timeout_in_ms\", conf.cas_contention_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.cas_contention_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.counter_write_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"counter_write_request_timeout_in_ms\", conf.counter_write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.counter_write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n\n        if(conf.truncate_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n        {\n           logInfo(\"truncate_request_timeout_in_ms\", conf.truncate_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n           conf.truncate_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n        }\n    }\n\n    private static void logInfo(String property, long actualValue, long lowestAcceptedValue)\n    {\n        logger.info(\"found {}::{} less than lowest acceptable value {}, continuing with {}\", property, actualValue, lowestAcceptedValue, lowestAcceptedValue);\n    }\n\n    public static void applyTokensConfig()\n    {\n        applyTokensConfig(conf);\n    }\n\n    static void applyTokensConfig(Config conf)\n    {\n        if (conf.initial_token != null)\n        {\n            Collection<String> tokens = tokensFromString(conf.initial_token);\n            if (conf.num_tokens == null)\n            {\n                if (tokens.size() == 1)\n                    conf.num_tokens = 1;\n                else\n                    throw new ConfigurationException(\"initial_token was set but num_tokens is not!\", false);\n            }\n\n            if (tokens.size() != conf.num_tokens)\n            {\n                throw new ConfigurationException(String.format(\"The number of initial tokens (by initial_token) specified (%s) is different from num_tokens value (%s)\",\n                                                               tokens.size(),\n                                                               conf.num_tokens),\n                                                 false);\n            }\n\n            for (String token : tokens)\n                partitioner.getTokenFactory().validate(token);\n        }\n        else if (conf.num_tokens == null)\n        {\n            conf.num_tokens = 1;\n        }\n    }\n\n    // definitely not safe for tools + clients - implicitly instantiates StorageService\n    public static void applySnitch()\n    {\n        /* end point snitch */\n        if (conf.endpoint_snitch == null)\n        {\n            throw new ConfigurationException(\"Missing endpoint_snitch directive\", false);\n        }\n        snitch = createEndpointSnitch(conf.dynamic_snitch, conf.endpoint_snitch);\n        EndpointSnitchInfo.create();\n\n        localDC = snitch.getLocalDatacenter();\n        localComparator = (replica1, replica2) -> {\n            boolean local1 = localDC.equals(snitch.getDatacenter(replica1));\n            boolean local2 = localDC.equals(snitch.getDatacenter(replica2));\n            if (local1 && !local2)\n                return -1;\n            if (local2 && !local1)\n                return 1;\n            return 0;\n        };\n    }\n\n    // definitely not safe for tools + clients - implicitly instantiates schema\n    public static void applyPartitioner()\n    {\n        applyPartitioner(conf);\n    }\n\n    public static void applyPartitioner(Config conf)\n    {\n        /* Hashing strategy */\n        if (conf.partitioner == null)\n        {\n            throw new ConfigurationException(\"Missing directive: partitioner\", false);\n        }\n        String name = conf.partitioner;\n        try\n        {\n            name = System.getProperty(Config.PROPERTY_PREFIX + \"partitioner\", conf.partitioner);\n            partitioner = FBUtilities.newPartitioner(name);\n        }\n        catch (Exception e)\n        {\n            throw new ConfigurationException(\"Invalid partitioner class \" + name, e);\n        }\n\n        paritionerName = partitioner.getClass().getCanonicalName();\n    }\n\n    /**\n     * Computes the sum of the 2 specified positive values returning {@code Long.MAX_VALUE} if the sum overflow.\n     *\n     * @param left the left operand\n     * @param right the right operand\n     * @return the sum of the 2 specified positive values of {@code Long.MAX_VALUE} if the sum overflow.\n     */\n    private static long saturatedSum(long left, long right)\n    {\n        assert left >= 0 && right >= 0;\n        long sum = left + right;\n        return sum < 0 ? Long.MAX_VALUE : sum;\n    }\n\n    private static FileStore guessFileStore(String dir) throws IOException\n    {\n        Path path = Paths.get(dir);\n        while (true)\n        {\n            try\n            {\n                return FileUtils.getFileStore(path);\n            }\n            catch (IOException e)\n            {\n                if (e instanceof NoSuchFileException)\n                {\n                    path = path.getParent();\n                    if (path == null)\n                    {\n                        throw new ConfigurationException(\"Unable to find filesystem for '\" + dir + \"'.\");\n                    }\n                }\n                else\n                {\n                    throw e;\n                }\n            }\n        }\n    }\n\n    private static long getUnallocatedSpace(String directory)\n    {\n        try\n        {\n            return guessFileStore(directory).getUnallocatedSpace();\n        }\n        catch (IOException e)\n        {\n            logger.debug(\"Error checking disk space\", e);\n            throw new ConfigurationException(String.format(\"Unable to check disk space available to %s. Perhaps the Cassandra user does not have the necessary permissions\",\n                                                           directory), e);\n        }\n    }\n\n    public static IEndpointSnitch createEndpointSnitch(boolean dynamic, String snitchClassName) throws ConfigurationException\n    {\n        if (!snitchClassName.contains(\".\"))\n            snitchClassName = \"org.apache.cassandra.locator.\" + snitchClassName;\n        IEndpointSnitch snitch = FBUtilities.construct(snitchClassName, \"snitch\");\n        return dynamic ? new DynamicEndpointSnitch(snitch) : snitch;\n    }\n\n    public static IAuthenticator getAuthenticator()\n    {\n        return authenticator;\n    }\n\n    public static void setAuthenticator(IAuthenticator authenticator)\n    {\n        DatabaseDescriptor.authenticator = authenticator;\n    }\n\n    public static IAuthorizer getAuthorizer()\n    {\n        return authorizer;\n    }\n\n    public static void setAuthorizer(IAuthorizer authorizer)\n    {\n        DatabaseDescriptor.authorizer = authorizer;\n    }\n\n    public static INetworkAuthorizer getNetworkAuthorizer()\n    {\n        return networkAuthorizer;\n    }\n\n    public static void setNetworkAuthorizer(INetworkAuthorizer networkAuthorizer)\n    {\n        DatabaseDescriptor.networkAuthorizer = networkAuthorizer;\n    }\n\n    public static IRoleManager getRoleManager()\n    {\n        return roleManager;\n    }\n\n    public static void setRoleManager(IRoleManager roleManager)\n    {\n        DatabaseDescriptor.roleManager = roleManager;\n    }\n\n    public static int getPermissionsValidity()\n    {\n        return conf.permissions_validity_in_ms;\n    }\n\n    public static void setPermissionsValidity(int timeout)\n    {\n        conf.permissions_validity_in_ms = timeout;\n    }\n\n    public static int getPermissionsUpdateInterval()\n    {\n        return conf.permissions_update_interval_in_ms == -1\n             ? conf.permissions_validity_in_ms\n             : conf.permissions_update_interval_in_ms;\n    }\n\n    public static void setPermissionsUpdateInterval(int updateInterval)\n    {\n        conf.permissions_update_interval_in_ms = updateInterval;\n    }\n\n    public static int getPermissionsCacheMaxEntries()\n    {\n        return conf.permissions_cache_max_entries;\n    }\n\n    public static int setPermissionsCacheMaxEntries(int maxEntries)\n    {\n        return conf.permissions_cache_max_entries = maxEntries;\n    }\n\n    public static int getRolesValidity()\n    {\n        return conf.roles_validity_in_ms;\n    }\n\n    public static void setRolesValidity(int validity)\n    {\n        conf.roles_validity_in_ms = validity;\n    }\n\n    public static int getRolesUpdateInterval()\n    {\n        return conf.roles_update_interval_in_ms == -1\n             ? conf.roles_validity_in_ms\n             : conf.roles_update_interval_in_ms;\n    }\n\n    public static void setRolesUpdateInterval(int interval)\n    {\n        conf.roles_update_interval_in_ms = interval;\n    }\n\n    public static int getRolesCacheMaxEntries()\n    {\n        return conf.roles_cache_max_entries;\n    }\n\n    public static int setRolesCacheMaxEntries(int maxEntries)\n    {\n        return conf.roles_cache_max_entries = maxEntries;\n    }\n\n    public static int getCredentialsValidity()\n    {\n        return conf.credentials_validity_in_ms;\n    }\n\n    public static void setCredentialsValidity(int timeout)\n    {\n        conf.credentials_validity_in_ms = timeout;\n    }\n\n    public static int getCredentialsUpdateInterval()\n    {\n        return conf.credentials_update_interval_in_ms == -1\n               ? conf.credentials_validity_in_ms\n               : conf.credentials_update_interval_in_ms;\n    }\n\n    public static void setCredentialsUpdateInterval(int updateInterval)\n    {\n        conf.credentials_update_interval_in_ms = updateInterval;\n    }\n\n    public static int getCredentialsCacheMaxEntries()\n    {\n        return conf.credentials_cache_max_entries;\n    }\n\n    public static int setCredentialsCacheMaxEntries(int maxEntries)\n    {\n        return conf.credentials_cache_max_entries = maxEntries;\n    }\n\n    public static int getMaxValueSize()\n    {\n        return conf.max_value_size_in_mb * 1024 * 1024;\n    }\n\n    public static void setMaxValueSize(int maxValueSizeInBytes)\n    {\n        conf.max_value_size_in_mb = maxValueSizeInBytes / 1024 / 1024;\n    }\n\n    /**\n     * Creates all storage-related directories.\n     */\n    public static void createAllDirectories()\n    {\n        try\n        {\n            if (conf.data_file_directories.length == 0)\n                throw new ConfigurationException(\"At least one DataFileDirectory must be specified\", false);\n\n            for (String dataFileDirectory : conf.data_file_directories)\n                FileUtils.createDirectory(dataFileDirectory);\n\n            if (conf.local_system_data_file_directory != null)\n                FileUtils.createDirectory(conf.local_system_data_file_directory);\n\n            if (conf.commitlog_directory == null)\n                throw new ConfigurationException(\"commitlog_directory must be specified\", false);\n            FileUtils.createDirectory(conf.commitlog_directory);\n\n            if (conf.hints_directory == null)\n                throw new ConfigurationException(\"hints_directory must be specified\", false);\n            FileUtils.createDirectory(conf.hints_directory);\n\n            if (conf.saved_caches_directory == null)\n                throw new ConfigurationException(\"saved_caches_directory must be specified\", false);\n            FileUtils.createDirectory(conf.saved_caches_directory);\n\n            if (conf.cdc_enabled)\n            {\n                if (conf.cdc_raw_directory == null)\n                    throw new ConfigurationException(\"cdc_raw_directory must be specified\", false);\n                FileUtils.createDirectory(conf.cdc_raw_directory);\n            }\n        }\n        catch (ConfigurationException e)\n        {\n            throw new IllegalArgumentException(\"Bad configuration; unable to start server: \"+e.getMessage());\n        }\n        catch (FSWriteError e)\n        {\n            throw new IllegalStateException(e.getCause().getMessage() + \"; unable to start server\");\n        }\n    }\n\n    public static IPartitioner getPartitioner()\n    {\n        return partitioner;\n    }\n\n    public static String getPartitionerName()\n    {\n        return paritionerName;\n    }\n\n    /* For tests ONLY, don't use otherwise or all hell will break loose. Tests should restore value at the end. */\n    public static IPartitioner setPartitionerUnsafe(IPartitioner newPartitioner)\n    {\n        IPartitioner old = partitioner;\n        partitioner = newPartitioner;\n        return old;\n    }\n\n    public static IEndpointSnitch getEndpointSnitch()\n    {\n        return snitch;\n    }\n    public static void setEndpointSnitch(IEndpointSnitch eps)\n    {\n        snitch = eps;\n    }\n\n    public static int getColumnIndexSize()\n    {\n        return (int) ByteUnit.KIBI_BYTES.toBytes(conf.column_index_size_in_kb);\n    }\n\n    public static int getColumnIndexSizeInKB()\n    {\n        return conf.column_index_size_in_kb;\n    }\n\n    @VisibleForTesting\n    public static void setColumnIndexSize(int val)\n    {\n        checkValidForByteConversion(val, \"column_index_size_in_kb\", ByteUnit.KIBI_BYTES);\n        conf.column_index_size_in_kb = val;\n    }\n\n    public static int getColumnIndexCacheSize()\n    {\n        return (int) ByteUnit.KIBI_BYTES.toBytes(conf.column_index_cache_size_in_kb);\n    }\n\n    public static int getColumnIndexCacheSizeInKB()\n    {\n        return conf.column_index_cache_size_in_kb;\n    }\n\n    public static void setColumnIndexCacheSize(int val)\n    {\n        checkValidForByteConversion(val, \"column_index_cache_size_in_kb\", ByteUnit.KIBI_BYTES);\n        conf.column_index_cache_size_in_kb = val;\n    }\n\n    public static int getBatchSizeWarnThreshold()\n    {\n        return (int) ByteUnit.KIBI_BYTES.toBytes(conf.batch_size_warn_threshold_in_kb);\n    }\n\n    public static int getBatchSizeWarnThresholdInKB()\n    {\n        return conf.batch_size_warn_threshold_in_kb;\n    }\n\n    public static long getBatchSizeFailThreshold()\n    {\n        return ByteUnit.KIBI_BYTES.toBytes(conf.batch_size_fail_threshold_in_kb);\n    }\n\n    public static int getBatchSizeFailThresholdInKB()\n    {\n        return conf.batch_size_fail_threshold_in_kb;\n    }\n\n    public static int getUnloggedBatchAcrossPartitionsWarnThreshold()\n    {\n        return conf.unlogged_batch_across_partitions_warn_threshold;\n    }\n\n    public static void setBatchSizeWarnThresholdInKB(int threshold)\n    {\n        checkValidForByteConversion(threshold, \"batch_size_warn_threshold_in_kb\", ByteUnit.KIBI_BYTES);\n        conf.batch_size_warn_threshold_in_kb = threshold;\n    }\n\n    public static void setBatchSizeFailThresholdInKB(int threshold)\n    {\n        conf.batch_size_fail_threshold_in_kb = threshold;\n    }\n\n    public static Collection<String> getInitialTokens()\n    {\n        return tokensFromString(System.getProperty(Config.PROPERTY_PREFIX + \"initial_token\", conf.initial_token));\n    }\n\n    public static String getAllocateTokensForKeyspace()\n    {\n        return System.getProperty(Config.PROPERTY_PREFIX + \"allocate_tokens_for_keyspace\", conf.allocate_tokens_for_keyspace);\n    }\n\n    public static Integer getAllocateTokensForLocalRf()\n    {\n        return conf.allocate_tokens_for_local_replication_factor;\n    }\n\n    public static Collection<String> tokensFromString(String tokenString)\n    {\n        List<String> tokens = new ArrayList<>();\n        if (tokenString != null)\n            for (String token : StringUtils.split(tokenString, ','))\n                tokens.add(token.trim());\n        return tokens;\n    }\n\n    public static int getNumTokens()\n    {\n        return conf.num_tokens;\n    }\n\n    public static InetAddressAndPort getReplaceAddress()\n    {\n        try\n        {\n            if (System.getProperty(Config.PROPERTY_PREFIX + \"replace_address\", null) != null)\n                return InetAddressAndPort.getByName(System.getProperty(Config.PROPERTY_PREFIX + \"replace_address\", null));\n            else if (System.getProperty(Config.PROPERTY_PREFIX + \"replace_address_first_boot\", null) != null)\n                return InetAddressAndPort.getByName(System.getProperty(Config.PROPERTY_PREFIX + \"replace_address_first_boot\", null));\n            return null;\n        }\n        catch (UnknownHostException e)\n        {\n            throw new RuntimeException(\"Replacement host name could not be resolved or scope_id was specified for a global IPv6 address\", e);\n        }\n    }\n\n    public static Collection<String> getReplaceTokens()\n    {\n        return tokensFromString(System.getProperty(Config.PROPERTY_PREFIX + \"replace_token\", null));\n    }\n\n    public static UUID getReplaceNode()\n    {\n        try\n        {\n            return UUID.fromString(System.getProperty(Config.PROPERTY_PREFIX + \"replace_node\", null));\n        } catch (NullPointerException e)\n        {\n            return null;\n        }\n    }\n\n    public static String getClusterName()\n    {\n        return conf.cluster_name;\n    }\n\n    public static int getStoragePort()\n    {\n        return Integer.parseInt(System.getProperty(Config.PROPERTY_PREFIX + \"storage_port\", Integer.toString(conf.storage_port)));\n    }\n\n    public static int getSSLStoragePort()\n    {\n        return Integer.parseInt(System.getProperty(Config.PROPERTY_PREFIX + \"ssl_storage_port\", Integer.toString(conf.ssl_storage_port)));\n    }\n\n    public static long nativeTransportIdleTimeout()\n    {\n        return conf.native_transport_idle_timeout_in_ms;\n    }\n\n    public static void setNativeTransportIdleTimeout(long nativeTransportTimeout)\n    {\n        conf.native_transport_idle_timeout_in_ms = nativeTransportTimeout;\n    }\n\n    public static long getRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setRpcTimeout(long timeOutInMillis)\n    {\n        conf.request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getReadRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.read_request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setReadRpcTimeout(long timeOutInMillis)\n    {\n        conf.read_request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getRangeRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.range_request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setRangeRpcTimeout(long timeOutInMillis)\n    {\n        conf.range_request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getWriteRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.write_request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setWriteRpcTimeout(long timeOutInMillis)\n    {\n        conf.write_request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getCounterWriteRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.counter_write_request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setCounterWriteRpcTimeout(long timeOutInMillis)\n    {\n        conf.counter_write_request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getCasContentionTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.cas_contention_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setCasContentionTimeout(long timeOutInMillis)\n    {\n        conf.cas_contention_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static long getTruncateRpcTimeout(TimeUnit unit)\n    {\n        return unit.convert(conf.truncate_request_timeout_in_ms, MILLISECONDS);\n    }\n\n    public static void setTruncateRpcTimeout(long timeOutInMillis)\n    {\n        conf.truncate_request_timeout_in_ms = timeOutInMillis;\n    }\n\n    public static boolean hasCrossNodeTimeout()\n    {\n        return conf.cross_node_timeout;\n    }\n\n    public static void setCrossNodeTimeout(boolean crossNodeTimeout)\n    {\n        conf.cross_node_timeout = crossNodeTimeout;\n    }\n\n    public static long getSlowQueryTimeout(TimeUnit units)\n    {\n        return units.convert(conf.slow_query_log_timeout_in_ms, MILLISECONDS);\n    }\n\n    /**\n     * @return the minimum configured {read, write, range, truncate, misc} timeout\n     */\n    public static long getMinRpcTimeout(TimeUnit unit)\n    {\n        return Longs.min(getRpcTimeout(unit),\n                         getReadRpcTimeout(unit),\n                         getRangeRpcTimeout(unit),\n                         getWriteRpcTimeout(unit),\n                         getCounterWriteRpcTimeout(unit),\n                         getTruncateRpcTimeout(unit));\n    }\n\n    public static long getPingTimeout(TimeUnit unit)\n    {\n        return unit.convert(getBlockForPeersTimeoutInSeconds(), TimeUnit.SECONDS);\n    }\n\n    public static double getPhiConvictThreshold()\n    {\n        return conf.phi_convict_threshold;\n    }\n\n    public static void setPhiConvictThreshold(double phiConvictThreshold)\n    {\n        conf.phi_convict_threshold = phiConvictThreshold;\n    }\n\n    public static int getConcurrentReaders()\n    {\n        return conf.concurrent_reads;\n    }\n\n    public static void setConcurrentReaders(int concurrent_reads)\n    {\n        if (concurrent_reads < 0)\n        {\n            throw new IllegalArgumentException(\"Concurrent reads must be non-negative\");\n        }\n        conf.concurrent_reads = concurrent_reads;\n    }\n\n    public static int getConcurrentWriters()\n    {\n        return conf.concurrent_writes;\n    }\n\n    public static void setConcurrentWriters(int concurrent_writers)\n    {\n        if (concurrent_writers < 0)\n        {\n            throw new IllegalArgumentException(\"Concurrent reads must be non-negative\");\n        }\n        conf.concurrent_writes = concurrent_writers;\n    }\n\n    public static int getConcurrentCounterWriters()\n    {\n        return conf.concurrent_counter_writes;\n    }\n\n    public static void setConcurrentCounterWriters(int concurrent_counter_writes)\n    {\n        if (concurrent_counter_writes < 0)\n        {\n            throw new IllegalArgumentException(\"Concurrent reads must be non-negative\");\n        }\n        conf.concurrent_counter_writes = concurrent_counter_writes;\n    }\n\n    public static int getConcurrentViewWriters()\n    {\n        return conf.concurrent_materialized_view_writes;\n    }\n\n    public static void setConcurrentViewWriters(int concurrent_materialized_view_writes)\n    {\n        if (concurrent_materialized_view_writes < 0)\n        {\n            throw new IllegalArgumentException(\"Concurrent reads must be non-negative\");\n        }\n        conf.concurrent_materialized_view_writes = concurrent_materialized_view_writes;\n    }\n\n    public static int getFlushWriters()\n    {\n        return conf.memtable_flush_writers;\n    }\n\n    public static int getConcurrentCompactors()\n    {\n        return conf.concurrent_compactors;\n    }\n\n    public static void setConcurrentCompactors(int value)\n    {\n        conf.concurrent_compactors = value;\n    }\n\n    public static int getCompactionThroughputMbPerSec()\n    {\n        return conf.compaction_throughput_mb_per_sec;\n    }\n\n    public static void setCompactionThroughputMbPerSec(int value)\n    {\n        conf.compaction_throughput_mb_per_sec = value;\n    }\n\n    public static long getCompactionLargePartitionWarningThreshold() { return ByteUnit.MEBI_BYTES.toBytes(conf.compaction_large_partition_warning_threshold_mb); }\n\n    public static int getConcurrentValidations()\n    {\n        return conf.concurrent_validations;\n    }\n\n    public static void setConcurrentValidations(int value)\n    {\n        value = value > 0 ? value : Integer.MAX_VALUE;\n        conf.concurrent_validations = value;\n    }\n\n    public static int getConcurrentViewBuilders()\n    {\n        return conf.concurrent_materialized_view_builders;\n    }\n\n    public static void setConcurrentViewBuilders(int value)\n    {\n        conf.concurrent_materialized_view_builders = value;\n    }\n\n    public static long getMinFreeSpacePerDriveInBytes()\n    {\n        return ByteUnit.MEBI_BYTES.toBytes(conf.min_free_space_per_drive_in_mb);\n    }\n\n    public static boolean getDisableSTCSInL0()\n    {\n        return disableSTCSInL0;\n    }\n\n    public static void setDisableSTCSInL0(boolean disabled)\n    {\n        disableSTCSInL0 = disabled;\n    }\n\n    public static int getStreamThroughputOutboundMegabitsPerSec()\n    {\n        return conf.stream_throughput_outbound_megabits_per_sec;\n    }\n\n    public static void setStreamThroughputOutboundMegabitsPerSec(int value)\n    {\n        conf.stream_throughput_outbound_megabits_per_sec = value;\n    }\n\n    public static int getInterDCStreamThroughputOutboundMegabitsPerSec()\n    {\n        return conf.inter_dc_stream_throughput_outbound_megabits_per_sec;\n    }\n\n    public static void setInterDCStreamThroughputOutboundMegabitsPerSec(int value)\n    {\n        conf.inter_dc_stream_throughput_outbound_megabits_per_sec = value;\n    }\n\n    /**\n     * Checks if the local system data must be stored in a specific location which supports redundancy.\n     *\n     * @return {@code true} if the local system keyspaces data must be stored in a different location,\n     * {@code false} otherwise.\n     */\n    public static boolean useSpecificLocationForLocalSystemData()\n    {\n        return conf.local_system_data_file_directory != null;\n    }\n\n    /**\n     * Returns the locations where the local system keyspaces data should be stored.\n     *\n     * <p>If the {@code local_system_data_file_directory} was unspecified, the local system keyspaces data should be stored\n     * in the first data directory. This approach guarantees that the server can tolerate the lost of all the disks but the first one.</p>\n     *\n     * @return the locations where should be stored the local system keyspaces data\n     */\n    public static String[] getLocalSystemKeyspacesDataFileLocations()\n    {\n        if (useSpecificLocationForLocalSystemData())\n            return new String[] {conf.local_system_data_file_directory};\n\n        return conf.data_file_directories.length == 0  ? conf.data_file_directories\n                                                       : new String[] {conf.data_file_directories[0]};\n    }\n\n    /**\n     * Returns the locations where the non local system keyspaces data should be stored.\n     *\n     * @return the locations where the non local system keyspaces data should be stored.\n     */\n    public static String[] getNonLocalSystemKeyspacesDataFileLocations()\n    {\n        return conf.data_file_directories;\n    }\n\n    /**\n     * Returns the list of all the directories where the data files can be stored (for local system and non local system keyspaces).\n     *\n     * @return the list of all the directories where the data files can be stored.\n     */\n    public static String[] getAllDataFileLocations()\n    {\n        if (conf.local_system_data_file_directory == null)\n            return conf.data_file_directories;\n\n        return ArrayUtils.addFirst(conf.data_file_directories, conf.local_system_data_file_directory);\n    }\n\n    public static String getCommitLogLocation()\n    {\n        return conf.commitlog_directory;\n    }\n\n    @VisibleForTesting\n    public static void setCommitLogLocation(String value)\n    {\n        conf.commitlog_directory = value;\n    }\n\n    public static ParameterizedClass getCommitLogCompression()\n    {\n        return conf.commitlog_compression;\n    }\n\n    public static void setCommitLogCompression(ParameterizedClass compressor)\n    {\n        conf.commitlog_compression = compressor;\n    }\n\n    public static Config.FlushCompression getFlushCompression()\n    {\n        return conf.flush_compression;\n    }\n\n    public static void setFlushCompression(Config.FlushCompression compression)\n    {\n        conf.flush_compression = compression;\n    }\n\n   /**\n    * Maximum number of buffers in the compression pool. The default value is 3, it should not be set lower than that\n    * (one segment in compression, one written to, one in reserve); delays in compression may cause the log to use\n    * more, depending on how soon the sync policy stops all writing threads.\n    */\n    public static int getCommitLogMaxCompressionBuffersInPool()\n    {\n        return conf.commitlog_max_compression_buffers_in_pool;\n    }\n\n    public static void setCommitLogMaxCompressionBuffersPerPool(int buffers)\n    {\n        conf.commitlog_max_compression_buffers_in_pool = buffers;\n    }\n\n    public static int getMaxMutationSize()\n    {\n        return (int) ByteUnit.KIBI_BYTES.toBytes(conf.max_mutation_size_in_kb);\n    }\n\n    public static int getTombstoneWarnThreshold()\n    {\n        return conf.tombstone_warn_threshold;\n    }\n\n    public static void setTombstoneWarnThreshold(int threshold)\n    {\n        conf.tombstone_warn_threshold = threshold;\n    }\n\n    public static int getTombstoneFailureThreshold()\n    {\n        return conf.tombstone_failure_threshold;\n    }\n\n    public static void setTombstoneFailureThreshold(int threshold)\n    {\n        conf.tombstone_failure_threshold = threshold;\n    }\n\n    public static int getCachedReplicaRowsWarnThreshold()\n    {\n        return conf.replica_filtering_protection.cached_rows_warn_threshold;\n    }\n\n    public static void setCachedReplicaRowsWarnThreshold(int threshold)\n    {\n        conf.replica_filtering_protection.cached_rows_warn_threshold = threshold;\n    }\n\n    public static int getCachedReplicaRowsFailThreshold()\n    {\n        return conf.replica_filtering_protection.cached_rows_fail_threshold;\n    }\n\n    public static void setCachedReplicaRowsFailThreshold(int threshold)\n    {\n        conf.replica_filtering_protection.cached_rows_fail_threshold = threshold;\n    }\n\n    /**\n     * size of commitlog segments to allocate\n     */\n    public static int getCommitLogSegmentSize()\n    {\n        return (int) ByteUnit.MEBI_BYTES.toBytes(conf.commitlog_segment_size_in_mb);\n    }\n\n    public static void setCommitLogSegmentSize(int sizeMegabytes)\n    {\n        conf.commitlog_segment_size_in_mb = sizeMegabytes;\n    }\n\n    public static String getSavedCachesLocation()\n    {\n        return conf.saved_caches_directory;\n    }\n\n    public static Set<InetAddressAndPort> getSeeds()\n    {\n        return ImmutableSet.<InetAddressAndPort>builder().addAll(seedProvider.getSeeds()).build();\n    }\n\n    public static SeedProvider getSeedProvider()\n    {\n        return seedProvider;\n    }\n\n    public static void setSeedProvider(SeedProvider newSeedProvider)\n    {\n        seedProvider = newSeedProvider;\n    }\n\n    public static InetAddress getListenAddress()\n    {\n        return listenAddress;\n    }\n\n    public static void setListenAddress(InetAddress newlistenAddress)\n    {\n        listenAddress = newlistenAddress;\n    }\n\n    public static InetAddress getBroadcastAddress()\n    {\n        return broadcastAddress;\n    }\n\n    public static boolean shouldListenOnBroadcastAddress()\n    {\n        return conf.listen_on_broadcast_address;\n    }\n\n    public static void setShouldListenOnBroadcastAddress(boolean shouldListenOnBroadcastAddress)\n    {\n        conf.listen_on_broadcast_address = shouldListenOnBroadcastAddress;\n    }\n\n    public static void setListenOnBroadcastAddress(boolean listen_on_broadcast_address)\n    {\n        conf.listen_on_broadcast_address = listen_on_broadcast_address;\n    }\n\n    public static IInternodeAuthenticator getInternodeAuthenticator()\n    {\n        return internodeAuthenticator;\n    }\n\n    public static void setInternodeAuthenticator(IInternodeAuthenticator internodeAuthenticator)\n    {\n        Preconditions.checkNotNull(internodeAuthenticator);\n        DatabaseDescriptor.internodeAuthenticator = internodeAuthenticator;\n    }\n\n    public static void setBroadcastAddress(InetAddress broadcastAdd)\n    {\n        broadcastAddress = broadcastAdd;\n    }\n\n    /**\n     * This is the address used to bind for the native protocol to communicate with clients. Most usages in the code\n     * refer to it as native address although some places still call it RPC address. It's not thrift RPC anymore\n     * so native is more appropriate. The address alone is not enough to uniquely identify this instance because\n     * multiple instances might use the same interface with different ports.\n     */\n    public static InetAddress getRpcAddress()\n    {\n        return rpcAddress;\n    }\n\n    public static void setBroadcastRpcAddress(InetAddress broadcastRPCAddr)\n    {\n        broadcastRpcAddress = broadcastRPCAddr;\n    }\n\n    /**\n     * This is the address used to reach this instance for the native protocol to communicate with clients. Most usages in the code\n     * refer to it as native address although some places still call it RPC address. It's not thrift RPC anymore\n     * so native is more appropriate. The address alone is not enough to uniquely identify this instance because\n     * multiple instances might use the same interface with different ports.\n     *\n     * May be null, please use {@link FBUtilities#getBroadcastNativeAddressAndPort()} instead.\n     */\n    public static InetAddress getBroadcastRpcAddress()\n    {\n        return broadcastRpcAddress;\n    }\n\n    public static boolean getRpcKeepAlive()\n    {\n        return conf.rpc_keepalive;\n    }\n\n    public static int getInternodeSocketSendBufferSizeInBytes()\n    {\n        return conf.internode_socket_send_buffer_size_in_bytes;\n    }\n\n    public static int getInternodeSocketReceiveBufferSizeInBytes()\n    {\n        return conf.internode_socket_receive_buffer_size_in_bytes;\n    }\n\n    public static int getInternodeApplicationSendQueueCapacityInBytes()\n    {\n        return conf.internode_application_send_queue_capacity_in_bytes;\n    }\n\n    public static int getInternodeApplicationSendQueueReserveEndpointCapacityInBytes()\n    {\n        return conf.internode_application_send_queue_reserve_endpoint_capacity_in_bytes;\n    }\n\n    public static int getInternodeApplicationSendQueueReserveGlobalCapacityInBytes()\n    {\n        return conf.internode_application_send_queue_reserve_global_capacity_in_bytes;\n    }\n\n    public static int getInternodeApplicationReceiveQueueCapacityInBytes()\n    {\n        return conf.internode_application_receive_queue_capacity_in_bytes;\n    }\n\n    public static int getInternodeApplicationReceiveQueueReserveEndpointCapacityInBytes()\n    {\n        return conf.internode_application_receive_queue_reserve_endpoint_capacity_in_bytes;\n    }\n\n    public static int getInternodeApplicationReceiveQueueReserveGlobalCapacityInBytes()\n    {\n        return conf.internode_application_receive_queue_reserve_global_capacity_in_bytes;\n    }\n\n    public static int getInternodeTcpConnectTimeoutInMS()\n    {\n        return conf.internode_tcp_connect_timeout_in_ms;\n    }\n\n    public static void setInternodeTcpConnectTimeoutInMS(int value)\n    {\n        conf.internode_tcp_connect_timeout_in_ms = value;\n    }\n\n    public static int getInternodeTcpUserTimeoutInMS()\n    {\n        return conf.internode_tcp_user_timeout_in_ms;\n    }\n\n    public static void setInternodeTcpUserTimeoutInMS(int value)\n    {\n        conf.internode_tcp_user_timeout_in_ms = value;\n    }\n\n    public static int getInternodeStreamingTcpUserTimeoutInMS()\n    {\n        return conf.internode_streaming_tcp_user_timeout_in_ms;\n    }\n\n    public static void setInternodeStreamingTcpUserTimeoutInMS(int value)\n    {\n        conf.internode_streaming_tcp_user_timeout_in_ms = value;\n    }\n\n    public static int getInternodeMaxMessageSizeInBytes()\n    {\n        return conf.internode_max_message_size_in_bytes;\n    }\n\n    @VisibleForTesting\n    public static void setInternodeMaxMessageSizeInBytes(int value)\n    {\n        conf.internode_max_message_size_in_bytes = value;\n    }\n\n    public static boolean startNativeTransport()\n    {\n        return conf.start_native_transport;\n    }\n\n    /**\n     *  This is the port used with RPC address for the native protocol to communicate with clients. Now that thrift RPC\n     *  is no longer in use there is no RPC port.\n     */\n    public static int getNativeTransportPort()\n    {\n        return Integer.parseInt(System.getProperty(Config.PROPERTY_PREFIX + \"native_transport_port\", Integer.toString(conf.native_transport_port)));\n    }\n\n    @VisibleForTesting\n    public static void setNativeTransportPort(int port)\n    {\n        conf.native_transport_port = port;\n    }\n\n    public static int getNativeTransportPortSSL()\n    {\n        return conf.native_transport_port_ssl == null ? getNativeTransportPort() : conf.native_transport_port_ssl;\n    }\n\n    @VisibleForTesting\n    public static void setNativeTransportPortSSL(Integer port)\n    {\n        conf.native_transport_port_ssl = port;\n    }\n\n    public static int getNativeTransportMaxThreads()\n    {\n        return conf.native_transport_max_threads;\n    }\n\n    public static void setNativeTransportMaxThreads(int max_threads)\n    {\n        conf.native_transport_max_threads = max_threads;\n    }\n\n    public static int getNativeTransportMaxFrameSize()\n    {\n        return (int) ByteUnit.MEBI_BYTES.toBytes(conf.native_transport_max_frame_size_in_mb);\n    }\n\n    public static long getNativeTransportMaxConcurrentConnections()\n    {\n        return conf.native_transport_max_concurrent_connections;\n    }\n\n    public static void setNativeTransportMaxConcurrentConnections(long nativeTransportMaxConcurrentConnections)\n    {\n        conf.native_transport_max_concurrent_connections = nativeTransportMaxConcurrentConnections;\n    }\n\n    public static long getNativeTransportMaxConcurrentConnectionsPerIp()\n    {\n        return conf.native_transport_max_concurrent_connections_per_ip;\n    }\n\n    public static void setNativeTransportMaxConcurrentConnectionsPerIp(long native_transport_max_concurrent_connections_per_ip)\n    {\n        conf.native_transport_max_concurrent_connections_per_ip = native_transport_max_concurrent_connections_per_ip;\n    }\n\n    public static boolean useNativeTransportLegacyFlusher()\n    {\n        return conf.native_transport_flush_in_batches_legacy;\n    }\n\n    public static boolean getNativeTransportAllowOlderProtocols()\n    {\n        return conf.native_transport_allow_older_protocols;\n    }\n\n    public static void setNativeTransportAllowOlderProtocols(boolean isEnabled)\n    {\n        conf.native_transport_allow_older_protocols = isEnabled;\n    }\n\n    public static double getCommitLogSyncGroupWindow()\n    {\n        return conf.commitlog_sync_group_window_in_ms;\n    }\n\n    public static void setCommitLogSyncGroupWindow(double windowMillis)\n    {\n        conf.commitlog_sync_group_window_in_ms = windowMillis;\n    }\n\n    public static int getNativeTransportReceiveQueueCapacityInBytes()\n    {\n        return conf.native_transport_receive_queue_capacity_in_bytes;\n    }\n\n    public static void setNativeTransportReceiveQueueCapacityInBytes(int queueSize)\n    {\n        conf.native_transport_receive_queue_capacity_in_bytes = queueSize;\n    }\n\n    public static long getNativeTransportMaxConcurrentRequestsInBytesPerIp()\n    {\n        return conf.native_transport_max_concurrent_requests_in_bytes_per_ip;\n    }\n\n    public static void setNativeTransportMaxConcurrentRequestsInBytesPerIp(long maxConcurrentRequestsInBytes)\n    {\n        conf.native_transport_max_concurrent_requests_in_bytes_per_ip = maxConcurrentRequestsInBytes;\n    }\n\n    public static long getNativeTransportMaxConcurrentRequestsInBytes()\n    {\n        return conf.native_transport_max_concurrent_requests_in_bytes;\n    }\n\n    public static void setNativeTransportMaxConcurrentRequestsInBytes(long maxConcurrentRequestsInBytes)\n    {\n        conf.native_transport_max_concurrent_requests_in_bytes = maxConcurrentRequestsInBytes;\n    }\n\n    public static int getCommitLogSyncPeriod()\n    {\n        return conf.commitlog_sync_period_in_ms;\n    }\n\n    public static long getPeriodicCommitLogSyncBlock()\n    {\n        Integer blockMillis = conf.periodic_commitlog_sync_lag_block_in_ms;\n        return blockMillis == null\n               ? (long)(getCommitLogSyncPeriod() * 1.5)\n               : blockMillis;\n    }\n\n    public static void setCommitLogSyncPeriod(int periodMillis)\n    {\n        conf.commitlog_sync_period_in_ms = periodMillis;\n    }\n\n    public static Config.CommitLogSync getCommitLogSync()\n    {\n        return conf.commitlog_sync;\n    }\n\n    public static void setCommitLogSync(CommitLogSync sync)\n    {\n        conf.commitlog_sync = sync;\n    }\n\n    public static Config.DiskAccessMode getDiskAccessMode()\n    {\n        return conf.disk_access_mode;\n    }\n\n    // Do not use outside unit tests.\n    @VisibleForTesting\n    public static void setDiskAccessMode(Config.DiskAccessMode mode)\n    {\n        conf.disk_access_mode = mode;\n    }\n\n    public static Config.DiskAccessMode getIndexAccessMode()\n    {\n        return indexAccessMode;\n    }\n\n    // Do not use outside unit tests.\n    @VisibleForTesting\n    public static void setIndexAccessMode(Config.DiskAccessMode mode)\n    {\n        indexAccessMode = mode;\n    }\n\n    public static void setDiskFailurePolicy(Config.DiskFailurePolicy policy)\n    {\n        conf.disk_failure_policy = policy;\n    }\n\n    public static Config.DiskFailurePolicy getDiskFailurePolicy()\n    {\n        return conf.disk_failure_policy;\n    }\n\n    public static void setCommitFailurePolicy(Config.CommitFailurePolicy policy)\n    {\n        conf.commit_failure_policy = policy;\n    }\n\n    public static Config.CommitFailurePolicy getCommitFailurePolicy()\n    {\n        return conf.commit_failure_policy;\n    }\n\n    public static boolean isSnapshotBeforeCompaction()\n    {\n        return conf.snapshot_before_compaction;\n    }\n\n    public static boolean isAutoSnapshot()\n    {\n        return conf.auto_snapshot;\n    }\n\n    @VisibleForTesting\n    public static void setAutoSnapshot(boolean autoSnapshot)\n    {\n        conf.auto_snapshot = autoSnapshot;\n    }\n    @VisibleForTesting\n    public static boolean getAutoSnapshot()\n    {\n        return conf.auto_snapshot;\n    }\n\n    public static long getSnapshotLinksPerSecond()\n    {\n        return conf.snapshot_links_per_second == 0 ? Long.MAX_VALUE : conf.snapshot_links_per_second;\n    }\n\n    public static void setSnapshotLinksPerSecond(long throttle)\n    {\n        if (throttle < 0)\n            throw new IllegalArgumentException(\"Invalid throttle for snapshot_links_per_second: must be positive\");\n\n        conf.snapshot_links_per_second = throttle;\n    }\n\n    public static RateLimiter getSnapshotRateLimiter()\n    {\n        return RateLimiter.create(getSnapshotLinksPerSecond());\n    }\n\n    public static boolean isAutoBootstrap()\n    {\n        return Boolean.parseBoolean(System.getProperty(Config.PROPERTY_PREFIX + \"auto_bootstrap\", Boolean.toString(conf.auto_bootstrap)));\n    }\n\n    public static void setHintedHandoffEnabled(boolean hintedHandoffEnabled)\n    {\n        conf.hinted_handoff_enabled = hintedHandoffEnabled;\n    }\n\n    public static boolean hintedHandoffEnabled()\n    {\n        return conf.hinted_handoff_enabled;\n    }\n\n    public static Set<String> hintedHandoffDisabledDCs()\n    {\n        return conf.hinted_handoff_disabled_datacenters;\n    }\n\n    public static void enableHintsForDC(String dc)\n    {\n        conf.hinted_handoff_disabled_datacenters.remove(dc);\n    }\n\n    public static void disableHintsForDC(String dc)\n    {\n        conf.hinted_handoff_disabled_datacenters.add(dc);\n    }\n\n    public static void setMaxHintWindow(int ms)\n    {\n        conf.max_hint_window_in_ms = ms;\n    }\n\n    public static int getMaxHintWindow()\n    {\n        return conf.max_hint_window_in_ms;\n    }\n\n    public static File getHintsDirectory()\n    {\n        return new File(conf.hints_directory);\n    }\n\n    public static File getSerializedCachePath(CacheType cacheType, String version, String extension)\n    {\n        String name = cacheType.toString()\n                + (version == null ? \"\" : '-' + version + '.' + extension);\n        return new File(conf.saved_caches_directory, name);\n    }\n\n    public static int getDynamicUpdateInterval()\n    {\n        return conf.dynamic_snitch_update_interval_in_ms;\n    }\n    public static void setDynamicUpdateInterval(int dynamicUpdateInterval)\n    {\n        conf.dynamic_snitch_update_interval_in_ms = dynamicUpdateInterval;\n    }\n\n    public static int getDynamicResetInterval()\n    {\n        return conf.dynamic_snitch_reset_interval_in_ms;\n    }\n    public static void setDynamicResetInterval(int dynamicResetInterval)\n    {\n        conf.dynamic_snitch_reset_interval_in_ms = dynamicResetInterval;\n    }\n\n    public static double getDynamicBadnessThreshold()\n    {\n        return conf.dynamic_snitch_badness_threshold;\n    }\n\n    public static void setDynamicBadnessThreshold(double dynamicBadnessThreshold)\n    {\n        conf.dynamic_snitch_badness_threshold = dynamicBadnessThreshold;\n    }\n\n    public static EncryptionOptions.ServerEncryptionOptions getInternodeMessagingEncyptionOptions()\n    {\n        return conf.server_encryption_options;\n    }\n\n    public static void setInternodeMessagingEncyptionOptions(EncryptionOptions.ServerEncryptionOptions encryptionOptions)\n    {\n        conf.server_encryption_options = encryptionOptions;\n    }\n\n    public static EncryptionOptions getNativeProtocolEncryptionOptions()\n    {\n        return conf.client_encryption_options;\n    }\n\n    @VisibleForTesting\n    public static void updateNativeProtocolEncryptionOptions(Function<EncryptionOptions, EncryptionOptions> update)\n    {\n        conf.client_encryption_options = update.apply(conf.client_encryption_options);\n    }\n\n    public static int getHintedHandoffThrottleInKB()\n    {\n        return conf.hinted_handoff_throttle_in_kb;\n    }\n\n    public static void setHintedHandoffThrottleInKB(int throttleInKB)\n    {\n        conf.hinted_handoff_throttle_in_kb = throttleInKB;\n    }\n\n    public static int getBatchlogReplayThrottleInKB()\n    {\n        return conf.batchlog_replay_throttle_in_kb;\n    }\n\n    public static void setBatchlogReplayThrottleInKB(int throttleInKB)\n    {\n        conf.batchlog_replay_throttle_in_kb = throttleInKB;\n    }\n\n    public static int getMaxHintsDeliveryThreads()\n    {\n        return conf.max_hints_delivery_threads;\n    }\n\n    public static int getHintsFlushPeriodInMS()\n    {\n        return conf.hints_flush_period_in_ms;\n    }\n\n    public static long getMaxHintsFileSize()\n    {\n        return  ByteUnit.MEBI_BYTES.toBytes(conf.max_hints_file_size_in_mb);\n    }\n\n    public static ParameterizedClass getHintsCompression()\n    {\n        return conf.hints_compression;\n    }\n\n    public static void setHintsCompression(ParameterizedClass parameterizedClass)\n    {\n        conf.hints_compression = parameterizedClass;\n    }\n\n    public static boolean isIncrementalBackupsEnabled()\n    {\n        return conf.incremental_backups;\n    }\n\n    public static void setIncrementalBackupsEnabled(boolean value)\n    {\n        conf.incremental_backups = value;\n    }\n\n    public static boolean getFileCacheEnabled()\n    {\n        return conf.file_cache_enabled;\n    }\n\n    public static int getFileCacheSizeInMB()\n    {\n        if (conf.file_cache_size_in_mb == null)\n        {\n            // In client mode the value is not set.\n            assert DatabaseDescriptor.isClientInitialized();\n            return 0;\n        }\n\n        return conf.file_cache_size_in_mb;\n    }\n\n    public static int getNetworkingCacheSizeInMB()\n    {\n        if (conf.networking_cache_size_in_mb == null)\n        {\n            // In client mode the value is not set.\n            assert DatabaseDescriptor.isClientInitialized();\n            return 0;\n        }\n        return conf.networking_cache_size_in_mb;\n    }\n\n    public static boolean getFileCacheRoundUp()\n    {\n        if (conf.file_cache_round_up == null)\n        {\n            // In client mode the value is not set.\n            assert DatabaseDescriptor.isClientInitialized();\n            return false;\n        }\n\n        return conf.file_cache_round_up;\n    }\n\n    public static DiskOptimizationStrategy getDiskOptimizationStrategy()\n    {\n        return diskOptimizationStrategy;\n    }\n\n    public static double getDiskOptimizationEstimatePercentile()\n    {\n        return conf.disk_optimization_estimate_percentile;\n    }\n\n    public static long getTotalCommitlogSpaceInMB()\n    {\n        return conf.commitlog_total_space_in_mb;\n    }\n\n    public static boolean shouldMigrateKeycacheOnCompaction()\n    {\n        return conf.key_cache_migrate_during_compaction;\n    }\n\n    public static void setMigrateKeycacheOnCompaction(boolean migrateCacheEntry)\n    {\n        conf.key_cache_migrate_during_compaction = migrateCacheEntry;\n    }\n\n    public static int getSSTablePreemptiveOpenIntervalInMB()\n    {\n        return FBUtilities.isWindows ? -1 : conf.sstable_preemptive_open_interval_in_mb;\n    }\n    public static void setSSTablePreemptiveOpenIntervalInMB(int mb)\n    {\n        conf.sstable_preemptive_open_interval_in_mb = mb;\n    }\n\n    public static boolean getTrickleFsync()\n    {\n        return conf.trickle_fsync;\n    }\n\n    public static int getTrickleFsyncIntervalInKb()\n    {\n        return conf.trickle_fsync_interval_in_kb;\n    }\n\n    public static long getKeyCacheSizeInMB()\n    {\n        return keyCacheSizeInMB;\n    }\n\n    public static long getIndexSummaryCapacityInMB()\n    {\n        return indexSummaryCapacityInMB;\n    }\n\n    public static int getKeyCacheSavePeriod()\n    {\n        return conf.key_cache_save_period;\n    }\n\n    public static void setKeyCacheSavePeriod(int keyCacheSavePeriod)\n    {\n        conf.key_cache_save_period = keyCacheSavePeriod;\n    }\n\n    public static int getKeyCacheKeysToSave()\n    {\n        return conf.key_cache_keys_to_save;\n    }\n\n    public static void setKeyCacheKeysToSave(int keyCacheKeysToSave)\n    {\n        conf.key_cache_keys_to_save = keyCacheKeysToSave;\n    }\n\n    public static String getRowCacheClassName()\n    {\n        return conf.row_cache_class_name;\n    }\n\n    public static long getRowCacheSizeInMB()\n    {\n        return conf.row_cache_size_in_mb;\n    }\n\n    @VisibleForTesting\n    public static void setRowCacheSizeInMB(long val)\n    {\n        conf.row_cache_size_in_mb = val;\n    }\n\n    public static int getRowCacheSavePeriod()\n    {\n        return conf.row_cache_save_period;\n    }\n\n    public static void setRowCacheSavePeriod(int rowCacheSavePeriod)\n    {\n        conf.row_cache_save_period = rowCacheSavePeriod;\n    }\n\n    public static int getRowCacheKeysToSave()\n    {\n        return conf.row_cache_keys_to_save;\n    }\n\n    public static long getCounterCacheSizeInMB()\n    {\n        return counterCacheSizeInMB;\n    }\n\n    public static void setRowCacheKeysToSave(int rowCacheKeysToSave)\n    {\n        conf.row_cache_keys_to_save = rowCacheKeysToSave;\n    }\n\n    public static int getCounterCacheSavePeriod()\n    {\n        return conf.counter_cache_save_period;\n    }\n\n    public static void setCounterCacheSavePeriod(int counterCacheSavePeriod)\n    {\n        conf.counter_cache_save_period = counterCacheSavePeriod;\n    }\n\n    public static int getCacheLoadTimeout()\n    {\n        return conf.cache_load_timeout_seconds;\n    }\n\n    @VisibleForTesting\n    public static void setCacheLoadTimeout(int seconds)\n    {\n        conf.cache_load_timeout_seconds = seconds;\n    }\n\n    public static int getCounterCacheKeysToSave()\n    {\n        return conf.counter_cache_keys_to_save;\n    }\n\n    public static void setCounterCacheKeysToSave(int counterCacheKeysToSave)\n    {\n        conf.counter_cache_keys_to_save = counterCacheKeysToSave;\n    }\n\n    public static int getStreamingKeepAlivePeriod()\n    {\n        return conf.streaming_keep_alive_period_in_secs;\n    }\n\n    public static int getStreamingConnectionsPerHost()\n    {\n        return conf.streaming_connections_per_host;\n    }\n\n    public static boolean streamEntireSSTables()\n    {\n        return conf.stream_entire_sstables;\n    }\n\n    public static String getLocalDataCenter()\n    {\n        return localDC;\n    }\n\n    public static Comparator<Replica> getLocalComparator()\n    {\n        return localComparator;\n    }\n\n    public static Config.InternodeCompression internodeCompression()\n    {\n        return conf.internode_compression;\n    }\n\n    public static void setInternodeCompression(Config.InternodeCompression compression)\n    {\n        conf.internode_compression = compression;\n    }\n\n    public static boolean getInterDCTcpNoDelay()\n    {\n        return conf.inter_dc_tcp_nodelay;\n    }\n\n    public static long getMemtableHeapSpaceInMb()\n    {\n        return conf.memtable_heap_space_in_mb;\n    }\n\n    public static long getMemtableOffheapSpaceInMb()\n    {\n        return conf.memtable_offheap_space_in_mb;\n    }\n\n    public static Config.MemtableAllocationType getMemtableAllocationType()\n    {\n        return conf.memtable_allocation_type;\n    }\n\n    public static int getRepairSessionMaxTreeDepth()\n    {\n        return conf.repair_session_max_tree_depth;\n    }\n\n    public static void setRepairSessionMaxTreeDepth(int depth)\n    {\n        if (depth < 10)\n            throw new ConfigurationException(\"Cannot set repair_session_max_tree_depth to \" + depth +\n                                             \" which is < 10, doing nothing\");\n        else if (depth > 20)\n            logger.warn(\"repair_session_max_tree_depth of \" + depth + \" > 20 could lead to excessive memory usage\");\n\n        conf.repair_session_max_tree_depth = depth;\n    }\n\n    public static int getRepairSessionSpaceInMegabytes()\n    {\n        return conf.repair_session_space_in_mb;\n    }\n\n    public static void setRepairSessionSpaceInMegabytes(int sizeInMegabytes)\n    {\n        if (sizeInMegabytes < 1)\n            throw new ConfigurationException(\"Cannot set repair_session_space_in_mb to \" + sizeInMegabytes +\n                                             \" < 1 megabyte\");\n        else if (sizeInMegabytes > (int) (Runtime.getRuntime().maxMemory() / (4 * 1048576)))\n            logger.warn(\"A repair_session_space_in_mb of \" + conf.repair_session_space_in_mb +\n                        \" megabytes is likely to cause heap pressure.\");\n\n        conf.repair_session_space_in_mb = sizeInMegabytes;\n    }\n\n    public static Float getMemtableCleanupThreshold()\n    {\n        return conf.memtable_cleanup_threshold;\n    }\n\n    public static int getIndexSummaryResizeIntervalInMinutes()\n    {\n        return conf.index_summary_resize_interval_in_minutes;\n    }\n\n    public static boolean hasLargeAddressSpace()\n    {\n        // currently we just check if it's a 64bit arch, but any we only really care if the address space is large\n        String datamodel = SUN_ARCH_DATA_MODEL.getString();\n        if (datamodel != null)\n        {\n            switch (datamodel)\n            {\n                case \"64\": return true;\n                case \"32\": return false;\n            }\n        }\n        String arch = OS_ARCH.getString();\n        return arch.contains(\"64\") || arch.contains(\"sparcv9\");\n    }\n\n    public static int getTracetypeRepairTTL()\n    {\n        return conf.tracetype_repair_ttl;\n    }\n\n    public static int getTracetypeQueryTTL()\n    {\n        return conf.tracetype_query_ttl;\n    }\n\n    public static int getWindowsTimerInterval()\n    {\n        return conf.windows_timer_interval;\n    }\n\n    public static long getPreparedStatementsCacheSizeMB()\n    {\n        return preparedStatementsCacheSizeInMB;\n    }\n\n    public static boolean enableUserDefinedFunctions()\n    {\n        return conf.enable_user_defined_functions;\n    }\n\n    public static boolean enableScriptedUserDefinedFunctions()\n    {\n        return conf.enable_scripted_user_defined_functions;\n    }\n\n    public static void enableScriptedUserDefinedFunctions(boolean enableScriptedUserDefinedFunctions)\n    {\n        conf.enable_scripted_user_defined_functions = enableScriptedUserDefinedFunctions;\n    }\n\n    public static boolean enableUserDefinedFunctionsThreads()\n    {\n        return conf.enable_user_defined_functions_threads;\n    }\n\n    public static long getUserDefinedFunctionWarnTimeout()\n    {\n        return conf.user_defined_function_warn_timeout;\n    }\n\n    public static void setUserDefinedFunctionWarnTimeout(long userDefinedFunctionWarnTimeout)\n    {\n        conf.user_defined_function_warn_timeout = userDefinedFunctionWarnTimeout;\n    }\n\n    public static boolean allowInsecureUDFs()\n    {\n        return conf.allow_insecure_udfs;\n    }\n\n    public static boolean allowExtraInsecureUDFs()\n    {\n        return conf.allow_extra_insecure_udfs;\n    }\n\n    public static boolean getEnableMaterializedViews()\n    {\n        return conf.enable_materialized_views;\n    }\n\n    public static void setEnableMaterializedViews(boolean enableMaterializedViews)\n    {\n        conf.enable_materialized_views = enableMaterializedViews;\n    }\n\n    public static boolean getEnableSASIIndexes()\n    {\n        return conf.enable_sasi_indexes;\n    }\n\n    public static void setEnableSASIIndexes(boolean enableSASIIndexes)\n    {\n        conf.enable_sasi_indexes = enableSASIIndexes;\n    }\n\n    public static boolean isTransientReplicationEnabled()\n    {\n        return conf.enable_transient_replication;\n    }\n\n    public static void setTransientReplicationEnabledUnsafe(boolean enabled)\n    {\n        conf.enable_transient_replication = enabled;\n    }\n\n    public static boolean enableDropCompactStorage()\n    {\n        return conf.enable_drop_compact_storage;\n    }\n\n    @VisibleForTesting\n    public static void setEnableDropCompactStorage(boolean enableDropCompactStorage)\n    {\n        conf.enable_drop_compact_storage = enableDropCompactStorage;\n    }\n\n    public static long getUserDefinedFunctionFailTimeout()\n    {\n        return conf.user_defined_function_fail_timeout;\n    }\n\n    public static void setUserDefinedFunctionFailTimeout(long userDefinedFunctionFailTimeout)\n    {\n        conf.user_defined_function_fail_timeout = userDefinedFunctionFailTimeout;\n    }\n\n    public static Config.UserFunctionTimeoutPolicy getUserFunctionTimeoutPolicy()\n    {\n        return conf.user_function_timeout_policy;\n    }\n\n    public static void setUserFunctionTimeoutPolicy(Config.UserFunctionTimeoutPolicy userFunctionTimeoutPolicy)\n    {\n        conf.user_function_timeout_policy = userFunctionTimeoutPolicy;\n    }\n\n    public static long getGCLogThreshold()\n    {\n        return conf.gc_log_threshold_in_ms;\n    }\n\n    public static EncryptionContext getEncryptionContext()\n    {\n        return encryptionContext;\n    }\n\n    public static long getGCWarnThreshold()\n    {\n        return conf.gc_warn_threshold_in_ms;\n    }\n\n    public static boolean isCDCEnabled()\n    {\n        return conf.cdc_enabled;\n    }\n\n    @VisibleForTesting\n    public static void setCDCEnabled(boolean cdc_enabled)\n    {\n        conf.cdc_enabled = cdc_enabled;\n    }\n\n    public static String getCDCLogLocation()\n    {\n        return conf.cdc_raw_directory;\n    }\n\n    public static int getCDCSpaceInMB()\n    {\n        return conf.cdc_total_space_in_mb;\n    }\n\n    @VisibleForTesting\n    public static void setCDCSpaceInMB(int input)\n    {\n        conf.cdc_total_space_in_mb = input;\n    }\n\n    public static int getCDCDiskCheckInterval()\n    {\n        return conf.cdc_free_space_check_interval_ms;\n    }\n\n    @VisibleForTesting\n    public static void setEncryptionContext(EncryptionContext ec)\n    {\n        encryptionContext = ec;\n    }\n\n    public static int searchConcurrencyFactor()\n    {\n        return searchConcurrencyFactor;\n    }\n\n    public static boolean isUnsafeSystem()\n    {\n        return unsafeSystem;\n    }\n\n    public static boolean diagnosticEventsEnabled()\n    {\n        return conf.diagnostic_events_enabled;\n    }\n\n    public static void setDiagnosticEventsEnabled(boolean enabled)\n    {\n        conf.diagnostic_events_enabled = enabled;\n    }\n\n    public static ConsistencyLevel getIdealConsistencyLevel()\n    {\n        return conf.ideal_consistency_level;\n    }\n\n    public static void setIdealConsistencyLevel(ConsistencyLevel cl)\n    {\n        conf.ideal_consistency_level = cl;\n    }\n\n    public static int getRepairCommandPoolSize()\n    {\n        return conf.repair_command_pool_size;\n    }\n\n    public static Config.RepairCommandPoolFullStrategy getRepairCommandPoolFullStrategy()\n    {\n        return conf.repair_command_pool_full_strategy;\n    }\n\n    public static FullQueryLoggerOptions getFullQueryLogOptions()\n    {\n        return  conf.full_query_logging_options;\n    }\n\n    public static boolean getBlockForPeersInRemoteDatacenters()\n    {\n        return conf.block_for_peers_in_remote_dcs;\n    }\n\n    public static int getBlockForPeersTimeoutInSeconds()\n    {\n        return conf.block_for_peers_timeout_in_secs;\n    }\n\n    public static boolean automaticSSTableUpgrade()\n    {\n        return conf.automatic_sstable_upgrade;\n    }\n\n    public static void setAutomaticSSTableUpgradeEnabled(boolean enabled)\n    {\n        if (conf.automatic_sstable_upgrade != enabled)\n            logger.debug(\"Changing automatic_sstable_upgrade to {}\", enabled);\n        conf.automatic_sstable_upgrade = enabled;\n    }\n\n    public static int maxConcurrentAutoUpgradeTasks()\n    {\n        return conf.max_concurrent_automatic_sstable_upgrades;\n    }\n\n    public static void setMaxConcurrentAutoUpgradeTasks(int value)\n    {\n        if (conf.max_concurrent_automatic_sstable_upgrades != value)\n            logger.debug(\"Changing max_concurrent_automatic_sstable_upgrades to {}\", value);\n        validateMaxConcurrentAutoUpgradeTasksConf(value);\n        conf.max_concurrent_automatic_sstable_upgrades = value;\n    }\n\n    private static void validateMaxConcurrentAutoUpgradeTasksConf(int value)\n    {\n        if (value < 0)\n            throw new ConfigurationException(\"max_concurrent_automatic_sstable_upgrades can't be negative\");\n        if (value > getConcurrentCompactors())\n            logger.warn(\"max_concurrent_automatic_sstable_upgrades ({}) is larger than concurrent_compactors ({})\", value, getConcurrentCompactors());\n    }\n    \n    public static AuditLogOptions getAuditLoggingOptions()\n    {\n        return conf.audit_logging_options;\n    }\n\n    public static void setAuditLoggingOptions(AuditLogOptions auditLoggingOptions)\n    {\n        conf.audit_logging_options = auditLoggingOptions;\n    }\n\n    public static Config.CorruptedTombstoneStrategy getCorruptedTombstoneStrategy()\n    {\n        return conf.corrupted_tombstone_strategy;\n    }\n\n    public static void setCorruptedTombstoneStrategy(Config.CorruptedTombstoneStrategy strategy)\n    {\n        conf.corrupted_tombstone_strategy = strategy;\n    }\n\n    public static boolean getRepairedDataTrackingForRangeReadsEnabled()\n    {\n        return conf.repaired_data_tracking_for_range_reads_enabled;\n    }\n\n    public static void setRepairedDataTrackingForRangeReadsEnabled(boolean enabled)\n    {\n        conf.repaired_data_tracking_for_range_reads_enabled = enabled;\n    }\n\n    public static boolean getRepairedDataTrackingForPartitionReadsEnabled()\n    {\n        return conf.repaired_data_tracking_for_partition_reads_enabled;\n    }\n\n    public static void setRepairedDataTrackingForPartitionReadsEnabled(boolean enabled)\n    {\n        conf.repaired_data_tracking_for_partition_reads_enabled = enabled;\n    }\n\n    public static boolean snapshotOnRepairedDataMismatch()\n    {\n        return conf.snapshot_on_repaired_data_mismatch;\n    }\n\n    public static void setSnapshotOnRepairedDataMismatch(boolean enabled)\n    {\n        conf.snapshot_on_repaired_data_mismatch = enabled;\n    }\n\n    public static boolean snapshotOnDuplicateRowDetection()\n    {\n        return conf.snapshot_on_duplicate_row_detection;\n    }\n\n    public static void setSnapshotOnDuplicateRowDetection(boolean enabled)\n    {\n        conf.snapshot_on_duplicate_row_detection = enabled;\n    }\n\n    public static boolean reportUnconfirmedRepairedDataMismatches()\n    {\n        return conf.report_unconfirmed_repaired_data_mismatches;\n    }\n\n    public static void reportUnconfirmedRepairedDataMismatches(boolean enabled)\n    {\n        conf.report_unconfirmed_repaired_data_mismatches = enabled;\n    }\n\n    public static boolean strictRuntimeChecks()\n    {\n        return strictRuntimeChecks;\n    }\n\n    public static boolean useOffheapMerkleTrees()\n    {\n        return conf.use_offheap_merkle_trees;\n    }\n\n    public static void useOffheapMerkleTrees(boolean value)\n    {\n        logger.info(\"Setting use_offheap_merkle_trees to {}\", value);\n        conf.use_offheap_merkle_trees = value;\n    }\n\n    public static Function<CommitLog, AbstractCommitLogSegmentManager> getCommitLogSegmentMgrProvider()\n    {\n        return commitLogSegmentMgrProvider;\n    }\n\n    public static void setCommitLogSegmentMgrProvider(Function<CommitLog, AbstractCommitLogSegmentManager> provider)\n    {\n        commitLogSegmentMgrProvider = provider;\n    }\n\n    /**\n     * Class that primarily tracks overflow thresholds during conversions\n     */\n    private enum ByteUnit {\n        KIBI_BYTES(2048 * 1024, 1024),\n        MEBI_BYTES(2048, 1024 * 1024);\n\n        private final int overflowThreshold;\n        private final int multiplier;\n\n        ByteUnit(int t, int m)\n        {\n            this.overflowThreshold = t;\n            this.multiplier = m;\n        }\n\n        public int overflowThreshold()\n        {\n            return overflowThreshold;\n        }\n\n        public boolean willOverflowInBytes(int val)\n        {\n            return val >= overflowThreshold;\n        }\n\n        public long toBytes(int val)\n        {\n            return val * multiplier;\n        }\n    }\n\n    /**\n     * Ensures passed in configuration value is positive and will not overflow when converted to Bytes\n     */\n    private static void checkValidForByteConversion(int val, final String name, final ByteUnit unit)\n    {\n        if (val < 0 || unit.willOverflowInBytes(val))\n            throw new ConfigurationException(String.format(\"%s must be positive value < %d, but was %d\",\n                                                           name, unit.overflowThreshold(), val), false);\n    }\n\n    public static int getValidationPreviewPurgeHeadStartInSec()\n    {\n        int seconds = conf.validation_preview_purge_head_start_in_sec;\n        return Math.max(seconds, 0);\n    }\n\n    public static boolean checkForDuplicateRowsDuringReads()\n    {\n        return conf.check_for_duplicate_rows_during_reads;\n    }\n\n    public static void setCheckForDuplicateRowsDuringReads(boolean enabled)\n    {\n        conf.check_for_duplicate_rows_during_reads = enabled;\n    }\n\n    public static boolean checkForDuplicateRowsDuringCompaction()\n    {\n        return conf.check_for_duplicate_rows_during_compaction;\n    }\n\n    public static void setCheckForDuplicateRowsDuringCompaction(boolean enabled)\n    {\n        conf.check_for_duplicate_rows_during_compaction = enabled;\n    }\n\n    public static int getRepairPendingCompactionRejectThreshold()\n    {\n        return conf.reject_repair_compaction_threshold;\n    }\n\n    public static void setRepairPendingCompactionRejectThreshold(int value)\n    {\n        conf.reject_repair_compaction_threshold = value;\n    }\n\n    public static int getInitialRangeTombstoneListAllocationSize()\n    {\n        return conf.initial_range_tombstone_list_allocation_size;\n    }\n\n    public static void setInitialRangeTombstoneListAllocationSize(int size)\n    {\n        conf.initial_range_tombstone_list_allocation_size = size;\n    }\n\n    public static double getRangeTombstoneListGrowthFactor()\n    {\n        return conf.range_tombstone_list_growth_factor;\n    }\n\n    public static void setRangeTombstoneListGrowthFactor(double resizeFactor)\n    {\n        conf.range_tombstone_list_growth_factor = resizeFactor;\n    }\n\n    public static boolean getAutocompactionOnStartupEnabled()\n    {\n        return conf.autocompaction_on_startup_enabled;\n    }\n\n    public static boolean autoOptimiseIncRepairStreams()\n    {\n        return conf.auto_optimise_inc_repair_streams;\n    }\n\n    public static void setAutoOptimiseIncRepairStreams(boolean enabled)\n    {\n        if (enabled != conf.auto_optimise_inc_repair_streams)\n            logger.info(\"Changing auto_optimise_inc_repair_streams from {} to {}\", conf.auto_optimise_inc_repair_streams, enabled);\n        conf.auto_optimise_inc_repair_streams = enabled;\n    }\n\n    public static boolean autoOptimiseFullRepairStreams()\n    {\n        return conf.auto_optimise_full_repair_streams;\n    }\n\n    public static void setAutoOptimiseFullRepairStreams(boolean enabled)\n    {\n        if (enabled != conf.auto_optimise_full_repair_streams)\n            logger.info(\"Changing auto_optimise_full_repair_streams from {} to {}\", conf.auto_optimise_full_repair_streams, enabled);\n        conf.auto_optimise_full_repair_streams = enabled;\n    }\n\n    public static boolean autoOptimisePreviewRepairStreams()\n    {\n        return conf.auto_optimise_preview_repair_streams;\n    }\n\n    public static void setAutoOptimisePreviewRepairStreams(boolean enabled)\n    {\n        if (enabled != conf.auto_optimise_preview_repair_streams)\n            logger.info(\"Changing auto_optimise_preview_repair_streams from {} to {}\", conf.auto_optimise_preview_repair_streams, enabled);\n        conf.auto_optimise_preview_repair_streams = enabled;\n    }\n\n    public static int tableCountWarnThreshold()\n    {\n        return conf.table_count_warn_threshold;\n    }\n\n    public static void setTableCountWarnThreshold(int value)\n    {\n        conf.table_count_warn_threshold = value;\n    }\n\n    public static int keyspaceCountWarnThreshold()\n    {\n        return conf.keyspace_count_warn_threshold;\n    }\n\n    public static void setKeyspaceCountWarnThreshold(int value)\n    {\n        conf.keyspace_count_warn_threshold = value;\n    }\n\n    public static int getConsecutiveMessageErrorsThreshold()\n    {\n        return conf.consecutive_message_errors_threshold;\n    }\n\n    public static void setConsecutiveMessageErrorsThreshold(int value)\n    {\n        conf.consecutive_message_errors_threshold = value;\n    }\n\n    public static boolean getForceNewPreparedStatementBehaviour()\n    {\n        return conf.force_new_prepared_statement_behaviour;\n    }\n\n    public static void setForceNewPreparedStatementBehaviour(boolean value)\n    {\n        if (value != conf.force_new_prepared_statement_behaviour)\n        {\n            logger.info(\"Setting force_new_prepared_statement_behaviour to {}\", value);\n            conf.force_new_prepared_statement_behaviour = value;\n        }\n    }\n}\n\n/**\n     * FOR TESTING PURPOSES\n     */\n@VisibleForTesting\n    synchronized public void stopUnsafe(boolean deleteSegments)\n    {\n        if (!started)\n            return;\n\n        started = false;\n        executor.shutdown();\n        try\n        {\n            executor.awaitTermination();\n        }\n        catch (InterruptedException e)\n        {\n            throw new RuntimeException(e);\n        }\n        segmentManager.stopUnsafe(deleteSegments);\n        CommitLogSegment.resetReplayLimit();\n        if (DatabaseDescriptor.isCDCEnabled() && deleteSegments)\n            for (File f : new File(DatabaseDescriptor.getCDCLogLocation()).listFiles())\n                FileUtils.deleteWithConfirm(f);\n    }\n\n    \npublic void handleMutation(Mutation m, int size, int entryLocation, CommitLogDescriptor desc)\n    {\n        if (DatabaseDescriptor.isCDCEnabled() && m.trackedByCDC())\n            sawCDCMutation = true;\n\n        pendingMutationBytes += size;\n        futures.offer(mutationInitiator.initiateMutation(m,\n                                                         desc.id,\n                                                         size,\n                                                         entryLocation,\n                                                         this));\n        // If there are finished mutations, or too many outstanding bytes/mutations\n        // drain the futures in the queue\n        while (futures.size() > MAX_OUTSTANDING_REPLAY_COUNT\n               || pendingMutationBytes > MAX_OUTSTANDING_REPLAY_BYTES\n               || (!futures.isEmpty() && futures.peek().isDone()))\n        {\n            pendingMutationBytes -= FBUtilities.waitOnFuture(futures.poll());\n        }\n    }\n\n    \n/**\n     * Creates a PartitionUpdate from a partition containing some schema table content.\n     * This is mainly calling {@code PartitionUpdate.fromIterator} except for the fact that it deals with\n     * the problem described in #12236.\n     */\nprivate static PartitionUpdate makeUpdateForSchema(UnfilteredRowIterator partition, ColumnFilter filter)\n    {\n        // This method is used during schema migration tasks, and if cdc is disabled, we want to force excluding the\n        // 'cdc' column from the TABLES/VIEWS schema table because it is problematic if received by older nodes (see #12236\n        // and #12697). Otherwise though, we just simply \"buffer\" the content of the partition into a PartitionUpdate.\n        if (DatabaseDescriptor.isCDCEnabled() || !TABLES_WITH_CDC_ADDED.contains(partition.metadata().name))\n            return PartitionUpdate.fromIterator(partition, filter);\n\n        // We want to skip the 'cdc' column. A simple solution for that is based on the fact that\n        // 'PartitionUpdate.fromIterator()' will ignore any columns that are marked as 'fetched' but not 'queried'.\n        ColumnFilter.Builder builder = ColumnFilter.allRegularColumnsBuilder(partition.metadata(), false);\n        for (ColumnMetadata column : filter.fetchedColumns())\n        {\n            if (!column.name.toString().equals(\"cdc\"))\n                builder.add(column);\n        }\n\n        return PartitionUpdate.fromIterator(partition, builder.build());\n    }\n\n    \nprivate static void addTableParamsToRowBuilder(TableParams params, Row.SimpleBuilder builder)\n    {\n        builder.add(\"bloom_filter_fp_chance\", params.bloomFilterFpChance)\n               .add(\"comment\", params.comment)\n               .add(\"dclocal_read_repair_chance\", 0.0) // no longer used, left for drivers' sake\n               .add(\"default_time_to_live\", params.defaultTimeToLive)\n               .add(\"gc_grace_seconds\", params.gcGraceSeconds)\n               .add(\"max_index_interval\", params.maxIndexInterval)\n               .add(\"memtable_flush_period_in_ms\", params.memtableFlushPeriodInMs)\n               .add(\"min_index_interval\", params.minIndexInterval)\n               .add(\"read_repair_chance\", 0.0) // no longer used, left for drivers' sake\n               .add(\"speculative_retry\", params.speculativeRetry.toString())\n               .add(\"additional_write_policy\", params.additionalWritePolicy.toString())\n               .add(\"crc_check_chance\", params.crcCheckChance)\n               .add(\"caching\", params.caching.asMap())\n               .add(\"compaction\", params.compaction.asMap())\n               .add(\"compression\", params.compression.asMap())\n               .add(\"read_repair\", params.readRepair.toString())\n               .add(\"extensions\", params.extensions);\n\n        // Only add CDC-enabled flag to schema if it's enabled on the node. This is to work around RTE's post-8099 if a 3.8+\n        // node sends table schema to a < 3.8 versioned node with an unknown column.\n        if (DatabaseDescriptor.isCDCEnabled())\n            builder.add(\"cdc\", params.cdc);\n    }\n\n    "
        },
        {
            "sender": "Developer Filter",
            "content": "Filter of the code context that is related to configuration: ```java\nprivate static boolean clientInitialized;\nprivate static boolean toolInitialized;\nprivate static boolean daemonInitialized;\n\npublic static void daemonInitialization(Supplier<Config> config) throws ConfigurationException\n{\n    if (toolInitialized)\n        throw new AssertionError(\"toolInitialization() already called\");\n    if (clientInitialized)\n        throw new AssertionError(\"clientInitialization() already called\");\n\n    // Some unit tests require this :(\n    if (daemonInitialized)\n        return;\n    daemonInitialized = true;\n\n    setConfig(config.get());\n    applyAll();\n    AuthConfig.applyAuth();\n}\n\nprivate static void applyAll() throws ConfigurationException\n{\n    //InetAddressAndPort cares that applySimpleConfig runs first\n    applySimpleConfig();\n\n    applyPartitioner();\n\n    applyAddressConfig();\n\n    applySnitch();\n\n    applyTokensConfig();\n\n    applySeedProvider();\n\n    applyEncryptionContext();\n\n    applySslContext();\n}\n\npublic static boolean isCDCEnabled()\n{\n    return conf.cdc_enabled;\n}\n\n@VisibleForTesting\npublic static void setCDCEnabled(boolean cdc_enabled)\n{\n    conf.cdc_enabled = cdc_enabled;\n}\n\npublic static void applySeedProvider()\n{\n    // load the seeds for node contact points\n    if (conf.seed_provider == null)\n    {\n        throw new ConfigurationException(\"seeds configuration is missing; a minimum of one seed is required.\", false);\n    }\n    try\n    {\n        Class<?> seedProviderClass = Class.forName(conf.seed_provider.class_name);\n        seedProvider = (SeedProvider)seedProviderClass.getConstructor(Map.class).newInstance(conf.seed_provider.parameters);\n    }\n    // there are about 5 checked exceptions that could be thrown here.\n    catch (Exception e)\n    {\n        throw new ConfigurationException(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\", true);\n    }\n    if (seedProvider.getSeeds().size() == 0)\n        throw new ConfigurationException(\"The seed provider lists no seeds.\", false);\n}\n\nif (conf.cdc_enabled)\n{\n    // Windows memory-mapped CommitLog files is incompatible with CDC as we hard-link files in cdc_raw. Confirm we don't have both enabled.\n    if (FBUtilities.isWindows && conf.commitlog_compression == null)\n        throw new ConfigurationException(\"Cannot enable cdc on Windows with uncompressed commitlog.\");\n\n    if (conf.cdc_raw_directory == null)\n    {\n        conf.cdc_raw_directory = storagedirFor(\"cdc_raw\");\n    }\n\n    if (conf.cdc_total_space_in_mb == 0)\n    {\n        final int preferredSizeInMB = 4096;\n        try\n        {\n            // use 1/8th of available space.  See discussion on #10013 and #10199 on the CL, taking half that for CDC\n            final long totalSpaceInBytes = guessFileStore(conf.cdc_raw_directory).getTotalSpace();\n            conf.cdc_total_space_in_mb = calculateDefaultSpaceInMB(\"cdc\",\n                                                                   conf.cdc_raw_directory,\n                                                                   \"cdc_total_space_in_mb\",\n                                                                   preferredSizeInMB,\n                                                                   totalSpaceInBytes, 1, 8);\n        }\n        catch (IOException e)\n        {\n            logger.debug(\"Error checking disk space\", e);\n            throw new ConfigurationException(String.format(\"Unable to check disk space available to '%s'. Perhaps the Cassandra user does not have the necessary permissions\",\n                                                           conf.cdc_raw_directory), e);\n        }\n    }\n\n    logger.info(\"cdc_enabled is true. Starting casssandra node with Change-Data-Capture enabled.\");\n}\n```"
        },
        {
            "sender": "Developer summary",
            "content": "Summary of the extracted code context: ### Configuration Summary for `DatabaseDescriptor`\n\n1. **Initialization Flags**:\n   - `clientInitialized`: Indicates if the client has been initialized.\n   - `toolInitialized`: Indicates if the tool has been initialized.\n   - `daemonInitialized`: Indicates if the daemon has been initialized.\n\n2. **Daemon Initialization**:\n   - Method: `daemonInitialization(Supplier<Config> config)`\n   - Ensures that the daemon is initialized only once and sets the configuration using the provided supplier. It calls `applyAll()` to apply various configuration settings.\n\n3. **Configuration Application**:\n   - Method: `applyAll()`\n   - Sequentially applies various configurations including:\n     - `applySimpleConfig()`\n     - `applyPartitioner()`\n     - `applyAddressConfig()`\n     - `applySnitch()`\n     - `applyTokensConfig()`\n     - `applySeedProvider()`\n     - `applyEncryptionContext()`\n     - `applySslContext()`\n\n4. **Change Data Capture (CDC)**:\n   - CDC is enabled via the configuration property `conf.cdc_enabled`.\n   - If enabled, it ensures that the commit log files are compatible with CDC and sets up the necessary directories and space allocation.\n\n5. **Seed Provider Configuration**:\n   - Method: `applySeedProvider()`\n   - Validates and initializes the seed provider for node contact points. It throws an error if no seeds are configured.\n\n6. **CDC Directory and Space Management**:\n   - If CDC is enabled, it sets the raw directory for CDC and calculates the total space allocated for CDC based on available disk space.\n\n### Key Configuration Properties:\n- `conf.cdc_enabled`: Boolean indicating if CDC is enabled.\n- `conf.seed_provider`: Configuration for seed provider settings.\n- `conf.cdc_raw_directory`: Directory for storing raw CDC data.\n- `conf.cdc_total_space_in_mb`: Total space allocated for CDC data.\n\nThis summary encapsulates the relevant configuration-related aspects of the `DatabaseDescriptor` class, focusing on initialization, configuration application, and CDC management."
        },
        {
            "sender": "performance agent Clarity Analysis",
            "content": "{\"Role\": \"You are a software performance engineer specializing in assessing code clarity for effective performance analysis.\", \"Requirement\": \"Check history conversation information and Review the provided configuration and code context to determine if all elements are sufficiently clear for performance analysis. Identify any methods that you think are important and could potentially hinder the performance evaluation for the configuration. Only list methods that have substantial ambiguity or are necessary for deeper understanding.\", \"Output Format\": \"For any unclear methods, respond with 'unclear method: method_name' and specify only the method name. If all elements are sufficiently clear, respond with 'clear for conducting performance analysis'.\", \"configuration_name\": \"cdc_enabled\", \"code_context\": \"```java\\nprivate static boolean clientInitialized;\\nprivate static boolean toolInitialized;\\nprivate static boolean daemonInitialized;\\n\\npublic static void daemonInitialization(Supplier<Config> config) throws ConfigurationException\\n{\\n    if (toolInitialized)\\n        throw new AssertionError(\\\"toolInitialization() already called\\\");\\n    if (clientInitialized)\\n        throw new AssertionError(\\\"clientInitialization() already called\\\");\\n\\n    // Some unit tests require this :(\\n    if (daemonInitialized)\\n        return;\\n    daemonInitialized = true;\\n\\n    setConfig(config.get());\\n    applyAll();\\n    AuthConfig.applyAuth();\\n}\\n\\nprivate static void applyAll() throws ConfigurationException\\n{\\n    //InetAddressAndPort cares that applySimpleConfig runs first\\n    applySimpleConfig();\\n\\n    applyPartitioner();\\n\\n    applyAddressConfig();\\n\\n    applySnitch();\\n\\n    applyTokensConfig();\\n\\n    applySeedProvider();\\n\\n    applyEncryptionContext();\\n\\n    applySslContext();\\n}\\n\\npublic static boolean isCDCEnabled()\\n{\\n    return conf.cdc_enabled;\\n}\\n\\n@VisibleForTesting\\npublic static void setCDCEnabled(boolean cdc_enabled)\\n{\\n    conf.cdc_enabled = cdc_enabled;\\n}\\n\\npublic static void applySeedProvider()\\n{\\n    // load the seeds for node contact points\\n    if (conf.seed_provider == null)\\n    {\\n        throw new ConfigurationException(\\\"seeds configuration is missing; a minimum of one seed is required.\\\", false);\\n    }\\n    try\\n    {\\n        Class<?> seedProviderClass = Class.forName(conf.seed_provider.class_name);\\n        seedProvider = (SeedProvider)seedProviderClass.getConstructor(Map.class).newInstance(conf.seed_provider.parameters);\\n    }\\n    // there are about 5 checked exceptions that could be thrown here.\\n    catch (Exception e)\\n    {\\n        throw new ConfigurationException(e.getMessage() + \\\"\\\\nFatal configuration error; unable to start server.  See log for stacktrace.\\\", true);\\n    }\\n    if (seedProvider.getSeeds().size() == 0)\\n        throw new ConfigurationException(\\\"The seed provider lists no seeds.\\\", false);\\n}\\n\\nif (conf.cdc_enabled)\\n{\\n    // Windows memory-mapped CommitLog files is incompatible with CDC as we hard-link files in cdc_raw. Confirm we don't have both enabled.\\n    if (FBUtilities.isWindows && conf.commitlog_compression == null)\\n        throw new ConfigurationException(\\\"Cannot enable cdc on Windows with uncompressed commitlog.\\\");\\n\\n    if (conf.cdc_raw_directory == null)\\n    {\\n        conf.cdc_raw_directory = storagedirFor(\\\"cdc_raw\\\");\\n    }\\n\\n    if (conf.cdc_total_space_in_mb == 0)\\n    {\\n        final int preferredSizeInMB = 4096;\\n        try\\n        {\\n            // use 1/8th of available space.  See discussion on #10013 and #10199 on the CL, taking half that for CDC\\n            final long totalSpaceInBytes = guessFileStore(conf.cdc_raw_directory).getTotalSpace();\\n            conf.cdc_total_space_in_mb = calculateDefaultSpaceInMB(\\\"cdc\\\",\\n                                                                   conf.cdc_raw_directory,\\n                                                                   \\\"cdc_total_space_in_mb\\\",\\n                                                                   preferredSizeInMB,\\n                                                                   totalSpaceInBytes, 1, 8);\\n        }\\n        catch (IOException e)\\n        {\\n            logger.debug(\\\"Error checking disk space\\\", e);\\n            throw new ConfigurationException(String.format(\\\"Unable to check disk space available to '%s'. Perhaps the Cassandra user does not have the necessary permissions\\\",\\n                                                           conf.cdc_raw_directory), e);\\n        }\\n    }\\n\\n    logger.info(\\\"cdc_enabled is true. Starting casssandra node with Change-Data-Capture enabled.\\\");\\n}\\n```\\n\\n--- Summary by Developer ---\\n### Configuration Summary for `DatabaseDescriptor`\\n\\n1. **Initialization Flags**:\\n   - `clientInitialized`: Indicates if the client has been initialized.\\n   - `toolInitialized`: Indicates if the tool has been initialized.\\n   - `daemonInitialized`: Indicates if the daemon has been initialized.\\n\\n2. **Daemon Initialization**:\\n   - Method: `daemonInitialization(Supplier<Config> config)`\\n   - Ensures that the daemon is initialized only once and sets the configuration using the provided supplier. It calls `applyAll()` to apply various configuration settings.\\n\\n3. **Configuration Application**:\\n   - Method: `applyAll()`\\n   - Sequentially applies various configurations including:\\n     - `applySimpleConfig()`\\n     - `applyPartitioner()`\\n     - `applyAddressConfig()`\\n     - `applySnitch()`\\n     - `applyTokensConfig()`\\n     - `applySeedProvider()`\\n     - `applyEncryptionContext()`\\n     - `applySslContext()`\\n\\n4. **Change Data Capture (CDC)**:\\n   - CDC is enabled via the configuration property `conf.cdc_enabled`.\\n   - If enabled, it ensures that the commit log files are compatible with CDC and sets up the necessary directories and space allocation.\\n\\n5. **Seed Provider Configuration**:\\n   - Method: `applySeedProvider()`\\n   - Validates and initializes the seed provider for node contact points. It throws an error if no seeds are configured.\\n\\n6. **CDC Directory and Space Management**:\\n   - If CDC is enabled, it sets the raw directory for CDC and calculates the total space allocated for CDC based on available disk space.\\n\\n### Key Configuration Properties:\\n- `conf.cdc_enabled`: Boolean indicating if CDC is enabled.\\n- `conf.seed_provider`: Configuration for seed provider settings.\\n- `conf.cdc_raw_directory`: Directory for storing raw CDC data.\\n- `conf.cdc_total_space_in_mb`: Total space allocated for CDC data.\\n\\nThis summary encapsulates the relevant configuration-related aspects of the `DatabaseDescriptor` class, focusing on initialization, configuration application, and CDC management.\", \"Reminder\": \"This is a follow-up review. Focus on previously unresolved methods or code elements to determine if they now have adequate context for performance analysis.\", \"The AI agent has analyzed the unclear method name\": \"reload\", \"Note\": \"The AI agent has analyzed the unclear method: reload and provided your requested information for further performance analysis.You must remember that you cannot ask the AI agent to analyze the same above methods again, no more information about the same method can be provided.\"}"
        },
        {
            "sender": "ClarityAnalysis",
            "content": "clear for conducting performance analysis"
        },
        {
            "sender": "performance agent sensitivity",
            "content": "{\"Role\": \"You are a Performance Sensitivity Agent responsible for determining if a configuration is performance-sensitive within a software system.\", \"Requirement\": \"Using developer-provided information as a secondary reference, analyze the configuration-related code to determine if it is performance-sensitive. Focus exclusively on configurations with substantial system-level performance impact due to time-intensive or memory-intensive operations. Only configurations that directly cause significant performance variations through extremely time-consuming or memory-heavy operations should be classified as performance-sensitive. Minor or moderate impacts should not be considered.\", \"Output Format\": \"Respond strictly in one of the following formats: 'The configuration is Performance Sensitive: reason' or 'The configuration is Performance Insensitive: reason'. No other response format is acceptable. Provide a concise yet clear and detailed reason for your classification.\", \"configuration_name\": \"cdc_enabled\", \"code_context\": \"```java\\nprivate static boolean clientInitialized;\\nprivate static boolean toolInitialized;\\nprivate static boolean daemonInitialized;\\n\\npublic static void daemonInitialization(Supplier<Config> config) throws ConfigurationException\\n{\\n    if (toolInitialized)\\n        throw new AssertionError(\\\"toolInitialization() already called\\\");\\n    if (clientInitialized)\\n        throw new AssertionError(\\\"clientInitialization() already called\\\");\\n\\n    // Some unit tests require this :(\\n    if (daemonInitialized)\\n        return;\\n    daemonInitialized = true;\\n\\n    setConfig(config.get());\\n    applyAll();\\n    AuthConfig.applyAuth();\\n}\\n\\nprivate static void applyAll() throws ConfigurationException\\n{\\n    //InetAddressAndPort cares that applySimpleConfig runs first\\n    applySimpleConfig();\\n\\n    applyPartitioner();\\n\\n    applyAddressConfig();\\n\\n    applySnitch();\\n\\n    applyTokensConfig();\\n\\n    applySeedProvider();\\n\\n    applyEncryptionContext();\\n\\n    applySslContext();\\n}\\n\\npublic static boolean isCDCEnabled()\\n{\\n    return conf.cdc_enabled;\\n}\\n\\n@VisibleForTesting\\npublic static void setCDCEnabled(boolean cdc_enabled)\\n{\\n    conf.cdc_enabled = cdc_enabled;\\n}\\n\\npublic static void applySeedProvider()\\n{\\n    // load the seeds for node contact points\\n    if (conf.seed_provider == null)\\n    {\\n        throw new ConfigurationException(\\\"seeds configuration is missing; a minimum of one seed is required.\\\", false);\\n    }\\n    try\\n    {\\n        Class<?> seedProviderClass = Class.forName(conf.seed_provider.class_name);\\n        seedProvider = (SeedProvider)seedProviderClass.getConstructor(Map.class).newInstance(conf.seed_provider.parameters);\\n    }\\n    // there are about 5 checked exceptions that could be thrown here.\\n    catch (Exception e)\\n    {\\n        throw new ConfigurationException(e.getMessage() + \\\"\\\\nFatal configuration error; unable to start server.  See log for stacktrace.\\\", true);\\n    }\\n    if (seedProvider.getSeeds().size() == 0)\\n        throw new ConfigurationException(\\\"The seed provider lists no seeds.\\\", false);\\n}\\n\\nif (conf.cdc_enabled)\\n{\\n    // Windows memory-mapped CommitLog files is incompatible with CDC as we hard-link files in cdc_raw. Confirm we don't have both enabled.\\n    if (FBUtilities.isWindows && conf.commitlog_compression == null)\\n        throw new ConfigurationException(\\\"Cannot enable cdc on Windows with uncompressed commitlog.\\\");\\n\\n    if (conf.cdc_raw_directory == null)\\n    {\\n        conf.cdc_raw_directory = storagedirFor(\\\"cdc_raw\\\");\\n    }\\n\\n    if (conf.cdc_total_space_in_mb == 0)\\n    {\\n        final int preferredSizeInMB = 4096;\\n        try\\n        {\\n            // use 1/8th of available space.  See discussion on #10013 and #10199 on the CL, taking half that for CDC\\n            final long totalSpaceInBytes = guessFileStore(conf.cdc_raw_directory).getTotalSpace();\\n            conf.cdc_total_space_in_mb = calculateDefaultSpaceInMB(\\\"cdc\\\",\\n                                                                   conf.cdc_raw_directory,\\n                                                                   \\\"cdc_total_space_in_mb\\\",\\n                                                                   preferredSizeInMB,\\n                                                                   totalSpaceInBytes, 1, 8);\\n        }\\n        catch (IOException e)\\n        {\\n            logger.debug(\\\"Error checking disk space\\\", e);\\n            throw new ConfigurationException(String.format(\\\"Unable to check disk space available to '%s'. Perhaps the Cassandra user does not have the necessary permissions\\\",\\n                                                           conf.cdc_raw_directory), e);\\n        }\\n    }\\n\\n    logger.info(\\\"cdc_enabled is true. Starting casssandra node with Change-Data-Capture enabled.\\\");\\n}\\n```\\n\\n--- Summary by Developer ---\\n### Configuration Summary for `DatabaseDescriptor`\\n\\n1. **Initialization Flags**:\\n   - `clientInitialized`: Indicates if the client has been initialized.\\n   - `toolInitialized`: Indicates if the tool has been initialized.\\n   - `daemonInitialized`: Indicates if the daemon has been initialized.\\n\\n2. **Daemon Initialization**:\\n   - Method: `daemonInitialization(Supplier<Config> config)`\\n   - Ensures that the daemon is initialized only once and sets the configuration using the provided supplier. It calls `applyAll()` to apply various configuration settings.\\n\\n3. **Configuration Application**:\\n   - Method: `applyAll()`\\n   - Sequentially applies various configurations including:\\n     - `applySimpleConfig()`\\n     - `applyPartitioner()`\\n     - `applyAddressConfig()`\\n     - `applySnitch()`\\n     - `applyTokensConfig()`\\n     - `applySeedProvider()`\\n     - `applyEncryptionContext()`\\n     - `applySslContext()`\\n\\n4. **Change Data Capture (CDC)**:\\n   - CDC is enabled via the configuration property `conf.cdc_enabled`.\\n   - If enabled, it ensures that the commit log files are compatible with CDC and sets up the necessary directories and space allocation.\\n\\n5. **Seed Provider Configuration**:\\n   - Method: `applySeedProvider()`\\n   - Validates and initializes the seed provider for node contact points. It throws an error if no seeds are configured.\\n\\n6. **CDC Directory and Space Management**:\\n   - If CDC is enabled, it sets the raw directory for CDC and calculates the total space allocated for CDC based on available disk space.\\n\\n### Key Configuration Properties:\\n- `conf.cdc_enabled`: Boolean indicating if CDC is enabled.\\n- `conf.seed_provider`: Configuration for seed provider settings.\\n- `conf.cdc_raw_directory`: Directory for storing raw CDC data.\\n- `conf.cdc_total_space_in_mb`: Total space allocated for CDC data.\\n\\nThis summary encapsulates the relevant configuration-related aspects of the `DatabaseDescriptor` class, focusing on initialization, configuration application, and CDC management.\", \"Reminder\": \"This is a follow-up sensitivity analysis. Re-evaluate the configuration, focusing on unresolved points from previous steps.\", \"Message from previous performance analysis\": \"reflection_needed: The analysis concludes that the `allocate_tokens_for_keyspace` configuration is performance sensitive, but it lacks a detailed examination of specific metrics or empirical data that demonstrate the impact of token allocation on system performance under various conditions. While it is acknowledged that opening a keyspace and retrieving its replication strategy can be time-consuming, the analysis should quantify how these operations affect latency and throughput in real-world scenarios, particularly with varying keyspace sizes and system loads. Additionally, the potential for resource contention during high-load scenarios needs to be elaborated with examples or data to strengthen the justification. Without this comprehensive analysis, the classification remains insufficient.\", \"Note\": \"Please review the previous message for further performance sensitivity analysis.\"}"
        },
        {
            "sender": "PerformanceSensitivity",
            "content": "The configuration is Performance Sensitive: The `cdc_enabled` configuration directly impacts the performance of the system by determining whether Change Data Capture (CDC) is active. When enabled, CDC can lead to significant memory and I/O overhead due to the need for additional disk space allocation for raw CDC data, as well as the potential for increased latency during write operations due to the management of commit logs. The operations involved in checking disk space and managing the CDC raw directory can be time-consuming, especially under high load or with large datasets, which can lead to performance degradation if not properly managed."
        },
        {
            "sender": "performance agent reflection",
            "content": "{\"Role\": \"You are a software performance engineer tasked with rigorously verifying conclusions from the performance sensitivity analysis.\", \"Requirement\": \"Critically assess the sensitivity analysis conclusions with a strict focus on performance impacts. If the configuration is deemed performance-sensitive, ensure that the justification provided is comprehensive, persuasive, and error-free. If any aspect appears insufficient or incorrect, specify your reasoning to aid re-evaluation.\", \"Output Format\": \"If all performance-sensitive aspects are addressed accurately, respond with 'analysis_complete: reason', including a clear explanation of why the analysis is correct. If any performance impact remains unclear or unresolved, respond in the exact format 'reflection_needed: reason', giving precise reasons for re-evaluation, with no variation in format.\", \"Reminder\": \"This is a follow-up reflection. Please review any unresolved issues from the previous performance analysis when verifying the sensitivity conclusions.\", \"Message from previous performance analysis\": \"The configuration is Performance Insensitive: The `cross_node_timeout` configuration primarily affects the logic for determining expiration times based on timestamps. The operations involved in the method `getExpiresAtNanos`\\u2014checking a boolean condition and performing basic arithmetic\\u2014are not time-intensive or memory-heavy. The impact on overall system performance is likely minor, as it does not involve significant resource consumption or complex computations that could lead to substantial performance variations. Therefore, it does not meet the criteria for being classified as performance-sensitive.\", \"Note\": \"The AI agent has provided suggestions for further performance analysis.\"}"
        },
        {
            "sender": "Reflection",
            "content": "analysis_complete: The analysis correctly identifies the `cross_node_timeout` configuration as performance insensitive. The justification provided is comprehensive, noting that the operations involved\u2014checking a boolean condition and performing basic arithmetic\u2014are not time-intensive or memory-heavy. The conclusion is supported by the understanding that these operations do not significantly consume resources or affect overall system performance. Therefore, the classification as performance insensitive is accurate and well-founded."
        }
    ]
}